# Ego-Exo Distilled RDT: Decoupled Diffusion Policy for VLA

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Diffusers](https://img.shields.io/badge/Diffusers-0.29+-yellow.svg)](https://huggingface.co/docs/diffusers/index)
[![PEFT](https://img.shields.io/badge/PEFT-LoRA-blue.svg)](https://github.com/huggingface/peft)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> **æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡åŒæ•™å¸ˆè’¸é¦ï¼ˆDual-Teacher Distillationï¼‰ä¸ä»»åŠ¡/èƒŒæ™¯è§£è€¦ï¼ˆTask/Background Decouplingï¼‰ï¼Œå®ç°åŸºäº"çº¯æ‰‹è…•è§†è§’"ï¼ˆWrist-View / Ego-Centricï¼‰çš„é«˜é²æ£’æ€§æœºå™¨äººæ“æ§æ¨¡å‹ã€‚

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„å…·èº«æ™ºèƒ½ï¼ˆEmbodied AIï¼‰ç³»ç»Ÿï¼Œç»“åˆäº† **VideoMAEv2** çš„æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ä¸ **Robotics Diffusion Transformer (RDT)** çš„åŠ¨ä½œç”Ÿæˆèƒ½åŠ›ã€‚

---

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

### ğŸ‘ï¸ çº¯æ‰‹è…•è§†è§’æ¨ç† (Ego-Centric Inference)
- è™½ç„¶è®­ç»ƒæ—¶åˆ©ç”¨å…¨å±€è§†è§’ï¼ˆThird-Viewï¼‰è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œä½†æ¨ç†æ—¶ä»…ä¾èµ–æ‰‹è…•ç›¸æœºè¾“å…¥
- è§£å†³äº†ç§»åŠ¨æ“ä½œä¸­ç¬¬ä¸‰æ–¹ç›¸æœºéš¾ä»¥å›ºå®šçš„ç—›ç‚¹

### âš¡ï¸ é«˜æ•ˆè®­ç»ƒæ¶æ„ (Latent Caching + LoRA)
- **Latent Caching**: é¢„å…ˆæå–å¹¶ç¼“å­˜ VideoMAE ç‰¹å¾ï¼Œæ¶ˆé™¤é‡å¤çš„è§†è§‰ç¼–ç è®¡ç®—ï¼Œè®­ç»ƒé€Ÿåº¦æå‡ 50x+
- **LoRA Fine-tuning**: å†»ç»“ 1.2B å‚æ•°çš„ä¸»å¹²ï¼Œä»…è®­ç»ƒ RDT çš„ Low-Rank é€‚é…å™¨ï¼ˆçº¦ 3.7M å‚æ•°ï¼‰ï¼Œæ˜¾å­˜å ç”¨å¤§å¹…é™ä½

### ğŸ“ åŒæ•™å¸ˆè’¸é¦æ¶æ„ (Dual-Teacher Distillation)
- **è¯­ä¹‰æ•™å¸ˆ (Semantic Teacher)**: ä½¿ç”¨å†»ç»“çš„ **SigLIP** (So400m) æä¾›å¼ºå¤§çš„å¼€æ”¾ä¸–ç•Œè¯­ä¹‰ç†è§£
- **æ—¶åº/æ‰‹éƒ¨æ•™å¸ˆ (Temporal Teacher)**: ä½¿ç”¨ **Exo-View** ç‰¹å¾ï¼ˆå¦‚æ‰‹éƒ¨è§†è§’ç‰¹å¾ï¼‰å¼ºåŒ–å¯¹åŠ¨ä½œç»†èŠ‚çš„æ•æ‰

### ğŸ¦¾ æ‰©æ•£ç­–ç•¥å¤§è„‘ (Diffusion Policy Head)
- é›†æˆ **RDT-1B** ä½œä¸ºç­–ç•¥å¤´ï¼Œé€šè¿‡ Early Fusion å°†æ„ŸçŸ¥ç‰¹å¾æ³¨å…¥
- é‡‡ç”¨ **DDIM Scheduler** è¿›è¡Œå»å™ªï¼Œåœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„åŒæ—¶ä¼˜åŒ–æ¨ç†å»¶è¿Ÿ

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

ç³»ç»Ÿåˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š

1. **Stage B (Distillation & Decoupling)**: è®­ç»ƒ `FusionEncoder`
   - å†»ç»“ VideoMAE ä¸»å¹²çš„å¤§éƒ¨åˆ†å±‚
   - è®­ç»ƒå¯¹é½å¤´å’Œè§£è€¦è·¯ç”±å±‚ï¼Œä½¿å…¶ç‰¹å¾é€¼è¿‘ SigLIP å’Œ Exo æ•™å¸ˆ

2. **Cache Latents (Pre-computation)**: ç‰¹å¾ç¼“å­˜
   - ä½¿ç”¨è®­ç»ƒå¥½çš„ Stage B Encoder æå–æ‰€æœ‰è§†é¢‘å¸§çš„ Latent ç‰¹å¾
   - ä¿å­˜ä¸º HDF5 æ ¼å¼ï¼Œä¾› Stage C æé€Ÿè¯»å–

3. **Stage C (Latent LoRA Tuning)**: è®­ç»ƒ `RDT Policy`
   - çº¯ç­–ç•¥å­¦ä¹ é˜¶æ®µï¼šç›´æ¥åŠ è½½ Latent ç‰¹å¾
   - ä½¿ç”¨ LoRA å¾®è°ƒ RDT ä¸»å¹²ï¼Œå®ç°æé€Ÿæ”¶æ•›ï¼ˆ~1000 samples/sï¼‰

---

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### ç¯å¢ƒé…ç½®

æ¨èä½¿ç”¨ Conda ç¯å¢ƒï¼š

```bash
# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda create -n ego_rdt python=3.10
conda activate ego_rdt

# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬è°ƒæ•´)
pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)

# å®‰è£…æ ¸å¿ƒä¾èµ– (æ–°å¢ peft)
pip install diffusers transformers timm einops h5py opencv-python accelerate peft
```

## ğŸš€ è®­ç»ƒæµç¨‹
### 1. Stage B: è’¸é¦ä¸è§£è€¦ (Distillation)
æ­¤é˜¶æ®µè®­ç»ƒ FusionEncoder ä»¥å¯¹é½æ•™å¸ˆç‰¹å¾ã€‚

```Bash
python train/stageB_train.py \
  --data_root /yanghaochuan/data/train_data.hdf5 \
  --output_dir /yanghaochuan/checkpoints \
  --batch_size 48 \
  --epochs 5
```

### 2. Cache Latents: ç‰¹å¾ç¼“å­˜
åˆ©ç”¨è®­ç»ƒå¥½çš„ Stage B æ¨¡å‹æå–ç‰¹å¾ï¼Œç”Ÿæˆç¼“å­˜æ–‡ä»¶ã€‚

```Bash
python utils/cache_latents.py \
  --data_root /yanghaochuan/data/train_data.hdf5 \
  --stage_b_ckpt /yanghaochuan/checkpoints/stageB_final.pt \
  --output_path /yanghaochuan/data/latents_cache.hdf5
```

### 3. Stage C: LoRA ç­–ç•¥å­¦ä¹  (Latent + LoRA)
åŠ è½½ç¼“å­˜ç‰¹å¾ï¼Œä»…å¾®è°ƒ RDT çš„ LoRA å‚æ•°ã€‚

```Bash
python train/stageC_latent_lora.py \
  --cache_path /yanghaochuan/data/latents_cache.hdf5 \
  --output_dir /yanghaochuan/checkpoints \
  --batch_size 128 \
  --epochs 50
```
## ğŸ¤– æ¨ç†ä¸éƒ¨ç½²
åœ¨çº¿å®æ—¶æ¨ç† (GPU Server)
é‡‡ç”¨ Client-Server æ¶æ„ï¼ŒServer ç«¯è´Ÿè´£é‡å‹æ¨¡å‹æ¨ç†ï¼ŒClient ç«¯è´Ÿè´£æœºå™¨äººæ§åˆ¶ã€‚

å¯åŠ¨ GPU æ¨ç†æœåŠ¡:

```Bash
# Server ç«¯åŠ è½½ Stage B Encoder å’Œ Stage C LoRA æƒé‡
python -m inference.server_gpu_image
```
å¯åŠ¨æœºæ¢°è‡‚å®¢æˆ·ç«¯:

```Bash
# Client ç«¯é‡‡é›†å›¾åƒå¹¶æ‰§è¡ŒåŠ¨ä½œ
python inference/robot_policy_system.py
```
æ¨ç†ç‰¹æ€§ï¼š

Split Loading: åˆ†åˆ«åŠ è½½ Encoder æƒé‡å’Œ LoRA Policy æƒé‡

Optimized: å¯ç”¨ torch.compile åŠ é€Ÿ Encoderï¼Œä½¿ç”¨ DDIM Scheduler ç¨³å®šç”Ÿæˆ

Robustness: å†…ç½® Z-Score åå½’ä¸€åŒ–ä¸åŠ¨é‡/é‡åŠ›åç½®ç­–ç•¥ï¼Œè§£å†³é€šä¿¡å»¶è¿Ÿå¸¦æ¥çš„æ‚¬åœé—®é¢˜

## ğŸ“ Citation
å¦‚æœä½ ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```Bash
@misc{ego_exo_rdt_2025,
  author = {Haochuan Yang},
  title = {Ego-Exo Distilled RDT: A Decoupled Diffusion Policy for VLA},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
}
```
## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.