# Ego-Exo Distilled RDT: Decoupled Diffusion Policy for VLA

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Diffusers](https://img.shields.io/badge/Diffusers-0.29+-yellow.svg)](https://huggingface.co/docs/diffusers/index)
[![PEFT](https://img.shields.io/badge/PEFT-LoRA-blue.svg)](https://github.com/huggingface/peft)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> **æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡ **Modality Dropout**ï¼ˆæ¨¡æ€ä¸¢å¼ƒï¼‰ä¸ **Action Chunking**ï¼ˆåŠ¨ä½œåˆ†å—ï¼‰ï¼Œå®ç°åŸºäºâ€œçº¯æ‰‹è…•è§†è§’â€ï¼ˆWrist-View Onlyï¼‰çš„é«˜é²æ£’æ€§ã€é«˜æµç•…åº¦æœºå™¨äººæ“æ§æ¨¡å‹ã€‚

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„å…·èº«æ™ºèƒ½ï¼ˆEmbodied AIï¼‰ç³»ç»Ÿï¼Œç»“åˆäº† **VideoMAEv2** çš„æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ä¸ **Robotics Diffusion Transformer (RDT)** çš„é•¿åºåˆ—åŠ¨ä½œç”Ÿæˆèƒ½åŠ›ã€‚

---

## ğŸŒŸ ä¸»è¦ç‰¹æ€§ (Key Features)

### ğŸ‘ï¸ é²æ£’çš„å•æ‘„æ¨ç† (Robust Single-View Inference)
- **Modality Dropout**: è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒï¼ˆMaskï¼‰ä¸»æ‘„å›¾åƒï¼Œå¼ºè¿«æ¨¡å‹å­¦ä¹ ä»…ä¾èµ–æ‰‹è…•ç›¸æœºï¼ˆWrist Cameraï¼‰è¿›è¡Œå†³ç­–ã€‚
- **Fake Main View**: æ¨ç†æ—¶æ„é€ å…¨é»‘çš„ä¸»æ‘„è¾“å…¥ï¼Œä¸è®­ç»ƒæ—¶çš„ Dropout åˆ†å¸ƒä¿æŒä¸€è‡´ï¼Œå½»åº•è§£å†³â€œæ‚¬åœâ€å’Œåˆ†å¸ƒåç§»é—®é¢˜ã€‚
- **Consistency Loss**: å¼•å…¥ä¸€è‡´æ€§æŸå¤±ï¼Œå¼ºåˆ¶å•æ‘„ç‰¹å¾é€¼è¿‘åŒæ‘„ç‰¹å¾ã€‚

### ğŸŒŠ æµç•…çš„åŠ¨ä½œæ§åˆ¶ (Smooth Action Chunking)
- **Sequence Prediction**: æ¨¡å‹ä¸€æ¬¡é¢„æµ‹æœªæ¥ **16æ­¥ (Horizon=16)** çš„åŠ¨ä½œåºåˆ—ï¼Œè€Œéå•æ­¥é¢„æµ‹ã€‚
- **Async Execution**: æœºå™¨äººå¼‚æ­¥æ‰§è¡ŒåŠ¨ä½œåºåˆ—ï¼Œæ¶ˆé™¤é€šä¿¡å»¶è¿Ÿå¯¼è‡´çš„â€œå¡é¡¿â€ (Stop-and-Go)ï¼Œå®ç°ä¸æ»‘æ“ä½œã€‚

### ğŸ“ åŒæ•™å¸ˆè’¸é¦æ¶æ„ (Dual-Teacher Distillation)
- **è¯­ä¹‰æ•™å¸ˆ**: ä½¿ç”¨å†»ç»“çš„ **SigLIP** æä¾›å¼€æ”¾ä¸–ç•Œè¯­ä¹‰ç†è§£ã€‚
- **æ—¶åºæ•™å¸ˆ**: ä½¿ç”¨ **Exo-View** ç‰¹å¾å¼ºåŒ–åŠ¨ä½œç»†èŠ‚æ•æ‰ã€‚

### âš¡ï¸ é«˜æ•ˆè”åˆè®­ç»ƒ (Joint Training with LoRA)
- **End-to-End LoRA**: å†»ç»“ VideoMAE Backboneï¼Œä»…å¾®è°ƒ Projector å’Œ RDT çš„ LoRA é€‚é…å™¨ã€‚
- **Memory Efficient**: æ”¯æŒåœ¨æœ‰é™æ˜¾å­˜ä¸‹è¿›è¡Œç«¯åˆ°ç«¯çš„å¤šæ¨¡æ€è”åˆè®­ç»ƒã€‚

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

ç³»ç»Ÿåˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š

1. **Stage B (Feature Alignment)**: é¢„è®­ç»ƒ `FusionEncoder`
   - è®­ç»ƒ Projector å’Œè§£è€¦è·¯ç”±å±‚ï¼Œä½¿å…¶ç‰¹å¾é€¼è¿‘æ•™å¸ˆæ¨¡å‹ (SigLIP/Exo)ã€‚

2. **Compute Stats (Normalization)**: æ•°æ®ç»Ÿè®¡
   - è®¡ç®—åŠ¨ä½œç©ºé—´çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œé‡‡ç”¨ **Z-Score** å½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨ä½œè¾“å‡ºçš„ç²¾å‡†åº¦ã€‚

3. **Stage C (Joint Training)**: è”åˆè®­ç»ƒ `RDT Policy`
   - **è¾“å…¥**: åŒæ‘„è§†é¢‘ (Main + Wrist)ã€‚
   - **æœºåˆ¶**: å®æ—¶è¿›è¡Œ Modality Dropout (éšæœºæŠ¹é»‘ Main)ã€‚
   - **è¾“å‡º**: 16æ­¥åŠ¨ä½œåºåˆ— (Action Chunk)ã€‚
   - **ä¼˜åŒ–**: åŒæ—¶æ›´æ–° FusionEncoder çš„ Projector å’Œ RDT çš„ LoRA æƒé‡ã€‚

---

## ğŸ› ï¸ å®‰è£…æŒ‡å—

æ¨èä½¿ç”¨ Conda ç¯å¢ƒï¼š

```bash
# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda create -n ego_rdt python=3.10
conda activate ego_rdt

# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬è°ƒæ•´)
pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install diffusers transformers timm einops h5py opencv-python accelerate peft
```

## ğŸš€ è®­ç»ƒæµç¨‹
### 1. å‡†å¤‡ç»Ÿè®¡æ–‡ä»¶
è®¡ç®—æ•°æ®é›†çš„å‡å€¼å’Œæ–¹å·®ï¼Œç”¨äº Z-Score å½’ä¸€åŒ–ã€‚

```Bash
python utils/compute_stats.py \
  --data_root /yanghaochuan/data/train_data.hdf5 \
  --save_path /yanghaochuan/data/dataset_stats.json
```
### 2. Stage B: ç¼–ç å™¨é¢„è®­ç»ƒ (Optional but Recommended)
è®­ç»ƒ FusionEncoder ä»¥å¯¹é½æ•™å¸ˆç‰¹å¾ã€‚è¿™ä¸€æ­¥ç”Ÿæˆçš„æƒé‡å°†ä½œä¸º Stage C çš„åˆå§‹åŒ–ã€‚

```Bash
python train/stageB_train.py \
  --data_root /yanghaochuan/data/train_data.hdf5 \
  --output_dir /yanghaochuan/checkpoints \
  --batch_size 48 \
  --epochs 5
python train/stageB_train.py --data_root /yanghaochuan/data/1223pick_up_the_paper_cup.hdf5 --output_dir /yanghaochuan/checkpoints --batch_size 16 --epochs 5
```
### 3. Stage C: è”åˆè®­ç»ƒ (Joint Training)
è¿™æ˜¯æœ€å…³é”®çš„æ­¥éª¤ã€‚å¯ç”¨ Modality Dropout å’Œ Action Chunkingã€‚

```Bash
python train/stageC_joint.py \
  --data_root /yanghaochuan/data/train_data.hdf5 \
  --output_dir /yanghaochuan/checkpoints \
  --stage_b_ckpt /yanghaochuan/checkpoints/stageB_final.pt \
  --batch_size 16 \
  --epochs 50 \
  --pred_horizon 16
```
æ³¨æ„: å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œè¯·å‡å° batch_sizeã€‚æ­¤é˜¶æ®µä¸å†ä½¿ç”¨ Latent Cacheï¼Œè€Œæ˜¯ç«¯åˆ°ç«¯è®­ç»ƒä»¥æ”¯æŒåŠ¨æ€ Dropoutã€‚

## ğŸ¤– æ¨ç†ä¸éƒ¨ç½²
ç³»ç»Ÿé‡‡ç”¨ Client-Server æ¶æ„ï¼Œæ”¯æŒå¼‚æ­¥éé˜»å¡æ§åˆ¶ã€‚

### 1. å¯åŠ¨æ¨ç†æœåŠ¡ (GPU Server)
åŠ è½½è®­ç»ƒå¥½çš„ FusionEncoder å’Œ RDT LoRA æƒé‡ã€‚

```Bash
# Server ç«¯
python inference/server_gpu_image.py
```
(è¯·ç¡®ä¿ deploy_agent_safe.py ä¸­çš„ STAGE_C_PATH æŒ‡å‘æ–°çš„ checkpoint)

### 2. å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯ (Robot Client)
è¿æ¥æœºæ¢°è‡‚ä¸æ¨ç†æœåŠ¡å™¨ã€‚

```Bash
# Client ç«¯
python inference/robot_policy_system.py
```
#### æ¨ç†ç‰¹æ€§ï¼š

Single-View Input: ä»…éœ€æ‰‹è…•ç›¸æœºå›¾åƒï¼Œå†…éƒ¨è‡ªåŠ¨æ„é€  Fake Main Viewã€‚

Chunked Execution: æ¥æ”¶ 16 æ­¥åŠ¨ä½œåºåˆ—ï¼Œå¹¶åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å¼‚æ­¥è¯·æ±‚ä¸‹ä¸€æ¬¡æ¨ç†ï¼Œå®ç°æ— ç¼è¿æ¥ã€‚

Safety: å†…ç½®å…³èŠ‚é™ä½ä¸å¹³æ»‘æ’å€¼ä¿æŠ¤ã€‚

## ğŸ“ Citation
å¦‚æœä½ ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```Bash
@misc{ego_exo_rdt_2025,
  author = {Haochuan Yang},
  title = {Ego-Exo Distilled RDT: A Decoupled Diffusion Policy for VLA},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
}
```
## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.