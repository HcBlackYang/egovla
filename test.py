# import torch
# import h5py
# import os
# import numpy as np

# # ================= è·¯å¾„é…ç½® =================
# PATHS = {
#     "RDT_WEIGHTS": "/yanghaochuan/models/rdt-1b/pytorch_model.bin",
#     "CHECKPOINT":  "/yanghaochuan/checkpoints/1223stageB_papercup.pt",
#     "DATASET":     "/yanghaochuan/data/1223pick_up_the_paper_cup.hdf5"
# }
# # ===========================================

# def print_header(title):
#     print(f"\n{'='*20} {title} {'='*20}")

# def inspect_torch_file(path, label):
#     print_header(f"Inspecting {label}")
#     if not os.path.exists(path):
#         # è‡ªåŠ¨å°è¯•å¤‡é€‰æ–‡ä»¶å
#         if path.endswith("pytorch_model.bin"):
#             alt = path.replace("pytorch_model.bin", "diffusion_pytorch_model.bin")
#             if os.path.exists(alt): path = alt
        
#         if not os.path.exists(path):
#             print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {path}")
#             return

#     try:
#         # å°è¯•åŠ è½½ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬
#         try: data = torch.load(path, map_location='cpu')
#         except: data = torch.load(path, map_location='cpu', weights_only=False)
#     except Exception as e:
#         print(f"âŒ åŠ è½½å¤±è´¥: {e}")
#         return

#     # è¯†åˆ«æ˜¯å¦æ˜¯ Checkpoint æ ¼å¼
#     state_dict = data
#     if isinstance(data, dict) and 'state_dict' in data:
#         print(f"â„¹ï¸  æ ¼å¼: Checkpoint (åŒ…å« 'state_dict')")
#         if 'args' in data: 
#             print(f"â„¹ï¸  è®­ç»ƒå‚æ•° (Args): {data['args']}") # æ‰“å°è®­ç»ƒæ—¶çš„å‚æ•°é…ç½®
#         state_dict = data['state_dict']
    
#     print(f"â„¹ï¸  æ€» Key æ•°é‡: {len(state_dict)}")
    
#     # === 1. åªæœç´¢å…³é”®å¼ é‡ (é¿å…åˆ·å±) ===
#     watchlist = ["x_pos_embed", "pos_embed", "img_cond_pos_embed", "state_proj", "action_proj", "visual_proj"]
#     print("\nğŸ” --- å…³é”®å¼ é‡é€è§† (Filtered) ---")
#     found_any = False
    
#     for k, v in state_dict.items():
#         # åªæ‰“å° watchlist é‡Œçš„ï¼Œæˆ–è€…åŒ…å« 'embed' çš„å‰å‡ ä¸ª
#         if any(w in k for w in watchlist):
#             if torch.is_tensor(v):
#                 print(f"  â€¢ {k:<45} | Shape: {list(v.shape)}")
                
#                 # é’ˆå¯¹ x_pos_embed åšè¯¦ç»†ç»´åº¦åˆ†æ
#                 if "x_pos_embed" in k and v.dim() == 3:
#                     T = v.shape[1]
#                     print(f"    ğŸ‘‰ [æ·±åº¦åˆ†æ] é•¿åº¦={T}")
#                     if T == 34: print("       -> æ¨æµ‹ç»“æ„: Time(1) + Freq(1) + Action(32)")
#                     elif T == 67: print("       -> æ¨æµ‹ç»“æ„: Time(1) + Freq(1) + State(1) + Action(64)")
#                     elif T == 35: print("       -> æ¨æµ‹ç»“æ„: Time(1) + Freq(1) + State(1) + Action(32)")
#             found_any = True

#     if not found_any: print("  (æœªå‘ç°å…³é”®å¼ é‡ï¼Œå¯èƒ½æ˜¯ LoRA æƒé‡æˆ–ç»“æ„ä¸åŒ)")

#     # === 2. æ‰“å°å‰ 5 ä¸ª Key ä¾›å‚è€ƒ ===
#     print("\nğŸ“„ --- å¤´éƒ¨ Key é‡‡æ · (å‰5ä¸ª) ---")
#     for k in list(state_dict.keys())[:5]:
#         print(f"  â€¢ {k}")

# def inspect_hdf5_file(path, label):
#     print_header(f"Inspecting {label}")
#     if not os.path.exists(path):
#         print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {path}")
#         return

#     try:
#         with h5py.File(path, 'r') as f:
#             print(f"â„¹ï¸  æ ¹ç›®å½• Keys: {list(f.keys())}")
            
#             print("\nğŸ” --- æœç´¢ Action å’Œ Image æ•°æ® (æŠ½æ ·) ---")
#             matches_act = 0
#             matches_img = 0
            
#             # æ™ºèƒ½éå†ï¼šåªæ‰¾å…³é”®æ•°æ®é›†ï¼Œä¸éå†æ‰€æœ‰ demo
#             def sparse_visit(name, node):
#                 nonlocal matches_act, matches_img
                
#                 if isinstance(node, h5py.Dataset):
#                     lower_name = name.lower()
                    
#                     # 1. æ£€æŸ¥ Action (åªæ‰“å°å‰ 2 ä¸ªæ‰¾åˆ°çš„)
#                     if 'action' in lower_name and matches_act < 2:
#                         print(f"  â€¢ {name:<45} | Shape: {node.shape} | Type: {node.dtype}")
#                         data = node[:]
#                         print(f"    ğŸ‘‰ [ç»Ÿè®¡] Min={np.min(data):.2f}, Max={np.max(data):.2f}, Mean={np.mean(data):.2f}")
#                         matches_act += 1
                        
#                     # 2. æ£€æŸ¥ Image (åªæ‰“å°å‰ 2 ä¸ªæ‰¾åˆ°çš„)
#                     elif ('image' in lower_name or 'rgb' in lower_name) and matches_img < 2:
#                         print(f"  â€¢ {name:<45} | Shape: {node.shape}")
#                         matches_img += 1
            
#             # ä½¿ç”¨ visititems éå†ï¼Œä½†é€šè¿‡è®¡æ•°å™¨æ§åˆ¶è¾“å‡ºé‡
#             f.visititems(sparse_visit)
            
#             if matches_act == 0: 
#                 print("  âš ï¸ æœªæ‰¾åˆ°åä¸º 'action' çš„æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥å‘½å (å¦‚ 'actions', 'joint_states')")

#     except Exception as e:
#         print(f"âŒ è¯»å– HDF5 å¤±è´¥: {e}")

# if __name__ == "__main__":
#     # 1. æ£€æŸ¥ RDT åŸå§‹æƒé‡ (çœ‹çœ‹å®ƒæ˜¯ 32 è¿˜æ˜¯ 64)
#     inspect_torch_file(PATHS["RDT_WEIGHTS"], "RDT Base Weights (.bin)")
    
#     # 2. æ£€æŸ¥ Stage B Checkpoint (çœ‹çœ‹ä½ ä¹‹å‰çš„è®­ç»ƒä¿å­˜äº†ä»€ä¹ˆ)
#     inspect_torch_file(PATHS["CHECKPOINT"], "Stage B Checkpoint (.pt)")
    
#     # 3. æ£€æŸ¥æ•°æ®é›† (çœ‹çœ‹æ•°æ®é‡Œ Action åˆ°åº•æ˜¯å¤šé•¿)
#     inspect_hdf5_file(PATHS["DATASET"], "HDF5 Dataset")

import torch
import sys
import os
import torch
import torch.nn as nn

# ==========================================
# 1. å¼ºåŠ›ç¯å¢ƒé…ç½® (è§£å†³ ModuleNotFoundError)
# ==========================================
# RDT åº“çš„çœŸå®æ ¹ç›®å½•
RDT_ROOT = "/yanghaochuan/projects/RoboticsDiffusionTransformer"

print(f"ğŸ”„ [Step 1] åˆ‡æ¢å·¥ä½œç›®å½•åˆ° RDT æºç åº“: {RDT_ROOT}")
# ç‰©ç†åˆ‡æ¢ç›®å½•ï¼Œè®© python import models è‡ªç„¶æŒ‡å‘åº“æ–‡ä»¶
os.chdir(RDT_ROOT)

# æŠŠè·¯å¾„åŠ åˆ°æœ€å‰é¢
if RDT_ROOT not in sys.path:
    sys.path.insert(0, RDT_ROOT)

# ğŸ§¹ æ‰«é™¤éšœç¢ï¼šå¦‚æœä¹‹å‰é”™è¯¯åŠ è½½äº† 'models'ï¼ŒæŠŠå®ƒè¸¢å‡ºå†…å­˜
keys_to_clean = [k for k in sys.modules if k == 'models' or k.startswith('models.')]
if keys_to_clean:
    print(f"ğŸ§¹ [Step 2] æ¸…ç†å†²çªæ¨¡å—ç¼“å­˜: {len(keys_to_clean)} ä¸ª")
    for k in keys_to_clean:
        del sys.modules[k]

print("ğŸš€ [Step 3] å°è¯•å¯¼å…¥ RDT æ¨¡å‹ç±»...")

try:
    # ç°åœ¨çš„ç¯å¢ƒåº”è¯¥å’Œåœ¨ RDT æ ¹ç›®å½•è¿è¡Œä¸€æ¨¡ä¸€æ ·
    from models.rdt.model import MultimodalDiffusionTransformer
    ModelClass = MultimodalDiffusionTransformer
    print(f"âœ… æˆåŠŸå¯¼å…¥: {ModelClass.__name__}")
except ImportError:
    try:
        from models.rdt.model import RDT
        ModelClass = RDT
        print(f"âœ… æˆåŠŸå¯¼å…¥: {ModelClass.__name__}")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å½»åº•å¤±è´¥: {e}")
        sys.exit(1)

# ==========================================
# 2. å¼€å§‹æ ¸å¿ƒæµ‹è¯• (æµ‹å‡ºåˆ°åº•è°æ˜¯ 1152)
# ==========================================

def run_test():
    print("\n" + "="*50)
    print("ğŸ§ª è¯Šæ–­å¼€å§‹ï¼šæ¨¡å‹åˆ°åº•åƒå“ªä¸€å¥—å‚æ•°ï¼Ÿ")
    print("="*50)

    # å‡†å¤‡åŸºç¡€å‚æ•° (é˜²æ­¢æ— å…³æŠ¥é”™)
    base_kwargs = {
        'action_dim': 8, 'horizon': 64, 'pred_horizon': 64,
        'img_token_dim': 1152, 'lang_token_dim': 4096, 'state_token_dim': 128,
        'patch_size': 14, 'img_size': 224, 
        'img_adaptor': 'mlp2x_gelu', 'lang_adaptor': 'mlp2x_gelu', 'state_adaptor': 'mlp2x_gelu',
        'depth': 1, 'num_heads': 1 # è®¾å°ç‚¹ï¼Œè·‘å¾—å¿«
    }

    # --- æµ‹è¯• A: æ‰å¹³å‚æ•° (Kwargs) ---
    print("\nğŸ‘‰ æµ‹è¯• A: ä¼ å…¥æ‰å¹³å‚æ•° (kwargs['hidden_size'] = 2048)")
    kwargs_a = base_kwargs.copy()
    kwargs_a['hidden_size'] = 2048 # <--- æˆ‘ä»¬å¸Œæœ›ç”Ÿæ•ˆçš„å€¼
    
    try:
        model_a = ModelClass(**kwargs_a)
        
        # æ£€æŸ¥ç”Ÿæ•ˆæƒ…å†µ
        val_a = getattr(model_a, 'hidden_size', 'æœªæ‰¾åˆ°å±æ€§')
        
        # æ·±åº¦æ£€æŸ¥ï¼šçœ‹æ¨¡å‹å†…éƒ¨ç¬¬ä¸€ä¸ª Linear å±‚çš„ç»´åº¦
        linear_dim_a = "æœªçŸ¥"
        for m in model_a.modules():
            if isinstance(m, nn.Linear):
                linear_dim_a = m.out_features
                break
                
        print(f"   [ç»“æœ] model.hidden_size: {val_a}")
        print(f"   [ç»“æœ] å®é™… Linear ç»´åº¦:  {linear_dim_a}")
        
        if linear_dim_a == 2048:
            print("   ğŸ‰ ç»“è®ºï¼šæ‰å¹³ä¼ å‚æœ‰æ•ˆï¼")
        elif linear_dim_a == 1152:
            print("   âš ï¸ ç»“è®ºï¼šæ‰å¹³ä¼ å‚å¤±æ•ˆï¼æ¨¡å‹ä½¿ç”¨äº†é»˜è®¤å€¼ 1152ã€‚")
        else:
            print(f"   â“ ç»“è®ºï¼šå¥‡æ€ªçš„å€¼ {linear_dim_a}")
            
    except Exception as e:
        print(f"   âŒ æŠ¥é”™: {e}")


    # --- æµ‹è¯• B: åµŒå¥— Config (args.rdt) ---
    print("\nğŸ‘‰ æµ‹è¯• B: ä¼ å…¥åµŒå¥—ç»“æ„ (args.rdt['hidden_size'] = 2048)")
    
    class Args: pass
    args_b = Args()
    # æ¨¡æ‹Ÿ Config æ–‡ä»¶çš„åµŒå¥—ç»“æ„
    args_b.rdt = {'hidden_size': 2048} 
    # åŒæ—¶ä¹ŸæŠŠå…¶ä»–å‚æ•°èµ‹ç»™ args (æ··åˆæ¨¡å¼)
    for k, v in base_kwargs.items(): setattr(args_b, k, v)
    
    try:
        # æœ‰äº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒç›´æ¥ä¼ å¯¹è±¡ï¼Œæˆ‘ä»¬å…ˆè¯•è¯•
        model_b = ModelClass(args_b)
        
        val_b = getattr(model_b, 'hidden_size', 'æœªæ‰¾åˆ°å±æ€§')
        linear_dim_b = "æœªçŸ¥"
        for m in model_b.modules():
            if isinstance(m, nn.Linear):
                linear_dim_b = m.out_features
                break
                
        print(f"   [ç»“æœ] model.hidden_size: {val_b}")
        print(f"   [ç»“æœ] å®é™… Linear ç»´åº¦:  {linear_dim_b}")
        
        if linear_dim_b == 2048:
            print("   ğŸ‰ ç»“è®ºï¼šåµŒå¥—ç»“æ„æœ‰æ•ˆï¼å¿…é¡»æ„é€  args.rdtã€‚")
            
    except Exception as e:
        print(f"   âŒ æŠ¥é”™ (å¯èƒ½æ¨¡å‹ä¸æ”¯æŒå¯¹è±¡ä¼ å‚): {e}")
        
        # å¦‚æœå¯¹è±¡ä¼ å‚å¤±è´¥ï¼Œè¯•è¯•çº¯å­—å…¸åµŒå¥—
        print("   ğŸ”„ å°è¯•ä¼ çº¯å­—å…¸åµŒå¥—...")
        try:
            dict_b = base_kwargs.copy()
            dict_b['rdt'] = {'hidden_size': 2048}
            model_b_dict = ModelClass(dict_b)
            # æ£€æŸ¥...
            for m in model_b_dict.modules():
                if isinstance(m, nn.Linear):
                    print(f"   [å­—å…¸ç»“æœ] å®é™… Linear ç»´åº¦: {m.out_features}")
                    break
        except Exception as e2:
             print(f"   âŒ å­—å…¸ä¹ŸæŠ¥é”™: {e2}")

if __name__ == "__main__":
    run_test()