import torch
import cv2
import json
import numpy as np
from collections import deque
from diffusers import DDIMScheduler
import os
from torch.amp import autocast
from peft import LoraConfig, get_peft_model
from transformers import T5Tokenizer
import torch._dynamo

# === å¯¼å…¥ä½ çš„æ¨¡å‹ ===
from model.fusion_encoder import FusionEncoder
from model.rdt_model import RDTWrapper

# === åŸºç¡€è·¯å¾„é…ç½® ===
VIDEO_MAE_PATH = '/yanghaochuan/models/VideoMAEv2-Large'
RDT_PATH = '/yanghaochuan/models/rdt-1b'
STATS_PATH = "/yanghaochuan/data/1223dataset_stats.json"
TOKENIZER_PATH = "/yanghaochuan/models/flan-t5-large"

# [ä¿®æ”¹ç‚¹] ä¸å†éœ€è¦ Stage B è·¯å¾„ï¼Œç›´æ¥ç”¨ Stage C
STAGE_C_PATH = '/yanghaochuan/checkpoints/checkpoint_step_3200.pt'

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =============================================================================
# ğŸ›¡ï¸ å®‰å…¨æ§åˆ¶å™¨
# =============================================================================
class SafetyController:
    def __init__(self):
        # Franka å…³èŠ‚æé™ (å®‰å…¨ä½™é‡ 0.05)
        self.joint_limits_min = np.array([-2.89, -1.76, -2.89, -3.07, -2.89, -0.01, -2.89]) + 0.05
        self.joint_limits_max = np.array([ 2.89,  1.76,  2.89, -0.06,  2.89,  3.75,  2.89]) - 0.05

    def clip_actions(self, actions_batch):
        actions_np = np.array(actions_batch)
        joints = actions_np[:, :7]
        gripper = actions_np[:, 7:]
        # å…³èŠ‚é™ä½
        joints_clipped = np.clip(joints, self.joint_limits_min, self.joint_limits_max)
        return np.concatenate([joints_clipped, gripper], axis=1)

# =============================================================================
# ğŸ¤– å®æ—¶æ¨ç† Agent
# =============================================================================
class RealTimeAgent:
    def __init__(self):
        self.device = DEVICE
        self.safety = SafetyController() 
        self.pred_horizon = 64  # æ˜ç¡®æ¨¡å‹é¢„æµ‹é•¿åº¦

        print(f"[Agent] Loading Tokenizer from {TOKENIZER_PATH}...")
        try:
            self.tokenizer = T5Tokenizer.from_pretrained(TOKENIZER_PATH, local_files_only=True)
        except:
            self.tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-large")
        
        # --- 1. åŠ è½½ç»Ÿè®¡æ•°æ®å¹¶ä¿®æ­£ç»´åº¦ ---
        if not os.path.exists(STATS_PATH):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°ç»Ÿè®¡æ–‡ä»¶: {STATS_PATH}")
        with open(STATS_PATH, 'r') as f:
            stats = json.load(f)
        
        mean_raw = np.array(stats['action_mean'], dtype=np.float32)
        std_raw = np.array(stats['action_std'], dtype=np.float32)
        
        # å¼ºåˆ¶æˆªæ–­æˆ–è¡¥é½åˆ° 8 ç»´ (7 Joint + 1 Gripper)
        if mean_raw.shape[0] > 8:
            print(f"[Agent] âš ï¸ ç»Ÿè®¡æ•°æ®ç»´åº¦ {mean_raw.shape[0]} > 8ï¼Œè¿›è¡Œæˆªæ–­ã€‚")
            self.action_mean = mean_raw[:8]
            self.action_std = std_raw[:8]
        elif mean_raw.shape[0] == 7:
            print(f"[Agent] âš ï¸ ç»Ÿè®¡æ•°æ®ç»´åº¦ä¸º 7ï¼Œè¡¥é½ Gripper=0ã€‚")
            self.action_mean = np.concatenate([mean_raw, [0.0]])
            self.action_std = np.concatenate([std_raw, [1.0]])
        else:
            self.action_mean = mean_raw
            self.action_std = std_raw
            
        self.action_std = np.maximum(self.action_std, 1e-2)
        
        self._init_models()
        self._init_scheduler()
        
        self.window_size = 16
        self.video_buffer = deque(maxlen=self.window_size)
        self.state_buffer = deque(maxlen=self.window_size)
        self.first_frame_tensor = None
        self.text_tokens = None 
        
        self.default_prompt = "pick up the paper cup"
        print(f"[Agent] Prompt: '{self.default_prompt}'")

    def _init_models(self):
        print(f"[Agent] Initializing models on {self.device}...")
        try:
            # Init Base Models
            self.encoder = FusionEncoder(backbone_path=VIDEO_MAE_PATH, teacher_dim=1152).to(self.device).eval()
            self.policy = RDTWrapper(action_dim=8, model_path=RDT_PATH, rdt_cond_dim=768, pred_horizon=64).to(self.device).eval()
            
            # Load Stage C Checkpoint
            print(f"[Agent] ğŸš€ Loading Joint Checkpoint: {STAGE_C_PATH}")
            ckpt_c = torch.load(STAGE_C_PATH, map_location=self.device)

            # Load Policy (LoRA)
            peft_config = LoraConfig(
                r=16, lora_alpha=32,
                target_modules=["q_proj", "k_proj", "v_proj", "out_proj", "fc1", "fc2", "linear"], 
                lora_dropout=0.05, bias="none"
            )
            self.policy.rdt_model = get_peft_model(self.policy.rdt_model, peft_config)
            
            if 'rdt_state_dict' in ckpt_c:
                self.policy.load_state_dict(ckpt_c['rdt_state_dict'], strict=False)
            else:
                self.policy.load_state_dict(ckpt_c, strict=False)
            print("[Agent] âœ… Policy weights loaded.")

            # Load Encoder (Joint Finetuned)
            if 'encoder_state_dict' in ckpt_c:
                self.encoder.load_state_dict(ckpt_c['encoder_state_dict'], strict=False)
                print("[Agent] âœ… Encoder weights loaded from Stage C.")
            else:
                raise ValueError(f"âŒ ä¸¥é‡é”™è¯¯: {STAGE_C_PATH} ä¸­æ²¡æœ‰ 'encoder_state_dict'ï¼")
            
            # Compile (Optional)
            print("[Agent] Compiling FusionEncoder...")
            torch._dynamo.config.suppress_errors = True
            try:
                self.encoder = torch.compile(self.encoder, mode="default")
            except Exception as e:
                print(f"[Warning] Encoder compile failed: {e}")

        except Exception as e:
            print(f"[Error] Model Init Failed: {e}")
            raise e

    def _init_scheduler(self):
        self.scheduler = DDIMScheduler(
            num_train_timesteps=1000,
            beta_schedule="squaredcos_cap_v2",
            prediction_type="epsilon", 
            clip_sample=True
        )
        self.inference_steps = 25
        self.scheduler.set_timesteps(self.inference_steps)

    def reset_session(self, first_frame_img):
        print("[Agent] Resetting session...")
        self.video_buffer.clear()
        self.state_buffer.clear()
        
        # å¤„ç†é¦–å¸§
        ff_resized = cv2.resize(first_frame_img, (224, 224))
        ff_rgb = cv2.cvtColor(ff_resized, cv2.COLOR_BGR2RGB)
        wrist_tensor = torch.tensor(ff_rgb, dtype=torch.float32).permute(2, 0, 1) / 255.0
        
        # æ„é€ å…¨é»‘ä¸»æ‘„
        main_fake = torch.zeros_like(wrist_tensor)
        dual_frame = torch.stack([main_fake, wrist_tensor], dim=0)
        
        self.first_frame_tensor = dual_frame.unsqueeze(0).to(self.device)
        
        # ç¼–ç æŒ‡ä»¤
        tokens = self.tokenizer(
            self.default_prompt, return_tensors="pt", padding="max_length", max_length=16, truncation=True
        ).input_ids
        self.text_tokens = tokens.to(self.device)
        
        # é¢„å¡«å…… Buffer
        for _ in range(self.window_size):
            self.video_buffer.append(dual_frame) 
            self.state_buffer.append(np.zeros(8)) 

    @torch.no_grad()
    def step(self, current_frame, current_qpos):
        # 1. Image Preprocess
        frame_resized = cv2.resize(current_frame, (224, 224))
        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        wrist_tensor = torch.tensor(frame_rgb, dtype=torch.float32).permute(2, 0, 1) / 255.0
        
        main_fake = torch.zeros_like(wrist_tensor)
        combined_frame = torch.stack([main_fake, wrist_tensor], dim=0)
        
        # =========================================================================
        # [æ ¸å¿ƒä¿®å¤] é™æ€å›¾ç­–ç•¥ (Static Image Strategy)
        # æ¯æ¬¡æ¨ç†å‰ï¼Œæ¸…ç©º Bufferï¼Œç”¨ã€å½“å‰å¸§ã€‘å¡«æ»¡å®ƒã€‚
        # è§£å†³ä½é¢‘æ¨ç†å¯¼è‡´çš„ "è§†é¢‘æ—¶åºé”™ä¹±" é—®é¢˜ã€‚
        # =========================================================================
        self.video_buffer.clear()
        for _ in range(self.window_size):
            self.video_buffer.append(combined_frame)
        
        # 2. State Preprocess
        if len(current_qpos) == 7:
            current_qpos = list(current_qpos) + [0.0]
        
        # [Safety Fix] ä½¿ç”¨ Numpy åœ¨ CPU ä¸Šè®¡ç®—ï¼Œä¸è¦åˆ›å»º GPU Tensor
        qpos_np = np.array(current_qpos, dtype=np.float32)
        norm_qpos_np = (qpos_np - self.action_mean) / self.action_std
        
        # åŒæ ·æ¸…ç©º State Buffer å¹¶å¡«æ»¡
        self.state_buffer.clear()
        for _ in range(self.window_size):
            self.state_buffer.append(norm_qpos_np)
        
        # 3. Batch Construction
        # Video: [1, 2, 3, 16, 224, 224]
        vid_t = torch.stack(list(self.video_buffer)).to(self.device)
        vid_t = vid_t.permute(1, 2, 0, 3, 4).unsqueeze(0)
        
        # State: [1, 16, 8] - è¿™é‡Œæ‰æŠŠ NumPy è½¬ Tensor å¹¶ç§»åˆ° GPU
        state_t = torch.tensor(np.array(list(self.state_buffer)), dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # 4. Inference
        self.scheduler.set_timesteps(self.inference_steps)
        
        with autocast('cuda', dtype=torch.bfloat16):
            features = self.encoder(vid_t, self.text_tokens, state_t, self.first_frame_tensor)
            latents = torch.randn(1, self.pred_horizon, 8, device=self.device) 
            
            for t in self.scheduler.timesteps:
                model_input = self.scheduler.scale_model_input(latents, t)
                t_tensor = torch.tensor([t], device=self.device)
                noise_pred = self.policy(model_input, t_tensor, features)
                latents = self.scheduler.step(noise_pred, t, latents).prev_sample
            
        # 5. Post-process
        normalized_actions = latents[0].float()
        
        # [Safety Fix] å…ˆè½¬ CPU Numpyï¼Œå†è¿›è¡Œåå½’ä¸€åŒ–è¿ç®—
        action_pred_np = normalized_actions.detach().cpu().numpy() # [B, 8]
        denormalized_actions = action_pred_np * self.action_std + self.action_mean
        
        # å®‰å…¨é™ä½
        safe_actions = self.safety.clip_actions(denormalized_actions)
        return safe_actions.tolist()