# import sys
# import os
# import torch
# import torch.optim as optim
# import argparse
# import time
# import numpy as np
# import torch.nn.functional as F
# from torch.utils.data import DataLoader
# from torch.amp import autocast
# from diffusers import DDPMScheduler
# from peft import LoraConfig, get_peft_model
# from torch.utils.tensorboard import SummaryWriter # === [æ–°å¢] TensorBoard

# # === [æ–°å¢] WandB æ£€æŸ¥ä¸å¯¼å…¥ ===
# try:
#     import wandb
#     HAS_WANDB = True
# except ImportError:
#     HAS_WANDB = False
#     print("âš ï¸ WandB not found. Install with `pip install wandb` for better visualization.")

# # === æ€§èƒ½ä¼˜åŒ– ===
# torch.backends.cuda.enable_flash_sdp(True)
# torch.backends.cuda.enable_mem_efficient_sdp(True)
# torch.backends.cuda.enable_math_sdp(False)

# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# from model.fusion_encoder import FusionEncoder
# from model.rdt_model import RDTWrapper
# from utils.dataset_loader import RobotDataset
# from losses.consistency_loss import compute_consistency_loss

# # === è·¯å¾„é…ç½® ===
# VIDEO_MAE_PATH = '/yanghaochuan/models/VideoMAEv2-Large'
# RDT_PATH = '/yanghaochuan/models/rdt-1b'
# STATS_PATH = '/yanghaochuan/data/1223dataset_stats.json'

# def train_stage_c(args):
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
#     # ====================================================
#     # 0. åˆå§‹åŒ–å¯è§†åŒ–è®°å½•å™¨ (TensorBoard + WandB)
#     # ====================================================
#     # TensorBoard æ—¥å¿—ç›®å½• (é€šå¸¸æœåŠ¡å™¨ç½‘é¡µä¼šè¯»å–è¿™ä¸ªè·¯å¾„)
#     log_dir = os.path.join(args.output_dir, "logs")
#     os.makedirs(log_dir, exist_ok=True)
#     tb_writer = SummaryWriter(log_dir=log_dir)
#     print(f"ğŸ“ˆ TensorBoard logging to: {log_dir}")
    
#     # WandB åˆå§‹åŒ–
#     if args.use_wandb and HAS_WANDB:
#         wandb.init(
#             project="RDT-StageC-Joint",
#             name=f"run_horizon{args.pred_horizon}_{int(time.time())}",
#             config=vars(args)
#         )
#         print("ğŸš€ WandB logging enabled.")
    
#     print(f"=== Stage C Joint Training ===")
    
#     # ====================================================
#     # 1. æ¨¡å‹åŠ è½½ (FusionEncoder + RDT)
#     # ====================================================
#     print("Loading Models...")
#     fusion_encoder = FusionEncoder(backbone_path=VIDEO_MAE_PATH, teacher_dim=1152, rdt_dim=768).to(device)
    
#     # åŠ è½½ Stage B
#     if args.stage_b_ckpt and os.path.exists(args.stage_b_ckpt):
#         print(f"Loading Stage B: {args.stage_b_ckpt}")
#         ckpt = torch.load(args.stage_b_ckpt, map_location='cpu')
#         state_dict = ckpt['encoder_state_dict'] if 'encoder_state_dict' in ckpt else ckpt
#         fusion_encoder.load_state_dict(state_dict, strict=False)
    
#     # å†»ç»“ VideoMAE
#     fusion_encoder.eval() 
#     for param in fusion_encoder.parameters(): param.requires_grad = True 
#     for param in fusion_encoder.backbone.parameters(): param.requires_grad = False
#     if fusion_encoder.text_encoder:
#         for p in fusion_encoder.text_encoder.parameters(): p.requires_grad = False

#     # RDT Wrapper
#     rdt_wrapper = RDTWrapper(action_dim=8, model_path=RDT_PATH, pred_horizon=args.pred_horizon).to(device)
    
#     # RDT æƒé‡è‡ªåŠ¨åˆ‡ç‰‡åŠ è½½
#     if os.path.exists(RDT_PATH) or os.path.exists(os.path.join(RDT_PATH, "pytorch_model.bin")):
#         rdt_file = RDT_PATH if os.path.isfile(RDT_PATH) else os.path.join(RDT_PATH, "pytorch_model.bin")
#         if os.path.exists(rdt_file):
#             print("Loading RDT weights with auto-slicing...")
#             state_dict = torch.load(rdt_file, map_location='cpu')
#             if 'x_pos_embed' in state_dict:
#                 ckpt_pos = state_dict['x_pos_embed']
#                 curr_pos = rdt_wrapper.rdt_model.x_pos_embed
#                 if ckpt_pos.shape != curr_pos.shape:
#                     print(f"âœ‚ï¸ Slicing position embed: {ckpt_pos.shape} -> {curr_pos.shape}")
#                     state_dict['x_pos_embed'] = ckpt_pos[:, :curr_pos.shape[1], :]
#             rdt_wrapper.rdt_model.load_state_dict(state_dict, strict=False)

#     # LoRA
#     print("Applying LoRA...")
#     peft_config = LoraConfig(
#         r=16, lora_alpha=32, target_modules=["q_proj", "k_proj", "v_proj", "out_proj", "fc1", "fc2", "linear"], 
#         lora_dropout=0.05, bias="none"
#     )
#     rdt_wrapper.rdt_model = get_peft_model(rdt_wrapper.rdt_model, peft_config)
    
#     # ====================================================
#     # 2. ä¼˜åŒ–å™¨ & æ•°æ®
#     # ====================================================
#     params = [
#         {'params': filter(lambda p: p.requires_grad, rdt_wrapper.parameters()), 'lr': 1e-4},
#         {'params': filter(lambda p: p.requires_grad, fusion_encoder.parameters()), 'lr': 1e-5}
#     ]
#     optimizer = optim.AdamW(params, weight_decay=1e-4)
#     noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="squaredcos_cap_v2", prediction_type="sample")

#     print(f"Loading Dataset from {args.data_root}")
#     dataset = RobotDataset(hdf5_path=args.data_root, window_size=16, pred_horizon=args.pred_horizon, stats_path=STATS_PATH)
#     loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)

#     # ====================================================
#     # 3. è®­ç»ƒå¾ªç¯ (å¸¦å¯è§†åŒ–)
#     # ====================================================
#     print(">>> Training Started <<<")
#     global_step = 0
    
#     for epoch in range(args.epochs):
#         rdt_wrapper.train()
#         start_time = time.time()
        
#         for i, batch in enumerate(loader):
#             video = batch['video'].to(device, non_blocking=True) # [B, 2, 3, 16, H, W]
#             state = batch['state'].to(device, non_blocking=True)
#             text = batch['text_tokens'].to(device, non_blocking=True)
#             ff = batch['first_frame'].to(device, non_blocking=True)
#             actions = batch['action_target'].to(device, non_blocking=True)

#             # Modality Dropout
#             rand_val = torch.rand(1).item()
#             mask_type = "None"
#             if rand_val < 0.7:
#                  video[:, 0] = 0.0  # Mask Main
#                  mask_type = "Main_Masked"
#             elif rand_val < 0.8:
#                  video[:, 1] = 0.0  # Mask Wrist
#                  mask_type = "Wrist_Masked"
            
#             optimizer.zero_grad()
            
#             with autocast('cuda', dtype=torch.bfloat16):
#                 # Forward
#                 e_t = fusion_encoder(video, text, state, ff)['e_t']
                
#                 # Loss
#                 timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (actions.shape[0],), device=device).long()
#                 noise = torch.randn_like(actions)
#                 noisy_actions = noise_scheduler.add_noise(actions, noise, timesteps)
                
#                 conditions = {"e_t": e_t, "state": state[:, -1, :]}
#                 pred_noise = rdt_wrapper(noisy_actions, timesteps, conditions)
                
#                 loss_diff = F.mse_loss(pred_noise, noise)
#                 loss_cons = compute_consistency_loss(fusion_encoder, batch, device)
#                 total_loss = loss_diff + 0.1 * loss_cons

#             total_loss.backward()
#             torch.nn.utils.clip_grad_norm_(rdt_wrapper.parameters(), 1.0)
#             optimizer.step()
            
#             # --- æ—¥å¿—è®°å½• ---
#             if i % 10 == 0:
#                 # 1. æ‰“å°åˆ°æ§åˆ¶å°
#                 print(f"Epoch {epoch} [{i}/{len(loader)}] Loss: {total_loss.item():.4f} (Diff: {loss_diff.item():.4f} Cons: {loss_cons.item():.4f})")
                
#                 # 2. å†™å…¥ TensorBoard
#                 tb_writer.add_scalar('Train/Total_Loss', total_loss.item(), global_step)
#                 tb_writer.add_scalar('Train/Diff_Loss', loss_diff.item(), global_step)
#                 tb_writer.add_scalar('Train/Cons_Loss', loss_cons.item(), global_step)
                
#                 # 3. å†™å…¥ WandB
#                 if args.use_wandb and HAS_WANDB:
#                     wandb.log({
#                         "total_loss": total_loss.item(),
#                         "diff_loss": loss_diff.item(),
#                         "cons_loss": loss_cons.item(),
#                         "epoch": epoch
#                     }, step=global_step)
            
#             # --- è§†é¢‘å¯è§†åŒ– (æ¯ 500 æ­¥ä¸€æ¬¡) ---
#             if global_step % 500 == 0 and args.use_wandb and HAS_WANDB:
#                 # æå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„è§†é¢‘: [2, 3, 16, H, W]
#                 # View 0: Main, View 1: Wrist
#                 vid_sample = video[0].float().cpu().numpy() # [2, 3, 16, H, W]
                
#                 # è½¬æ¢ä¸º GIF æ ¼å¼ [T, C, H, W] -> wandb éœ€ [T, C, H, W]
#                 # æˆ‘ä»¬æŠŠ Main å’Œ Wrist æ‹¼åœ¨ä¸€èµ·æ˜¾ç¤º
#                 main_view = vid_sample[0] # [3, 16, H, W] -> [16, 3, H, W]
#                 wrist_view = vid_sample[1]
                
#                 # å¤„ç†ä¸€ä¸‹ç»´åº¦é¡ºåºç»™ wandb: (Time, Channel, Height, Width)
#                 main_view = np.transpose(main_view, (1, 0, 2, 3))
#                 wrist_view = np.transpose(wrist_view, (1, 0, 2, 3))
                
#                 # æ‹¼æ¥: å·¦å³æ‹¼æ¥
#                 combined_view = np.concatenate([main_view, wrist_view], axis=3) # Width ç»´åº¦æ‹¼æ¥
                
#                 # è®°å½•è§†é¢‘
#                 wandb.log({
#                     "input_video": wandb.Video((combined_view * 255).astype(np.uint8), fps=4, format="gif", caption=f"E{epoch}-S{i}: {mask_type}")
#                 }, step=global_step)
#                 print("ğŸ¥ Video sample uploaded to WandB.")

#             global_step += 1

#         # ä¿å­˜ Checkpoint
#         if epoch % 5 == 0 or epoch == args.epochs - 1:
#             save_path = os.path.join(args.output_dir, f"epoch_{epoch}.pt")
#             torch.save({
#                 'epoch': epoch,
#                 'rdt_state_dict': rdt_wrapper.state_dict(),
#                 'encoder_state_dict': fusion_encoder.state_dict(),
#                 'optimizer_state_dict': optimizer.state_dict(),
#                 'pred_horizon': args.pred_horizon
#             }, save_path)
#             print(f"âœ… Saved to {save_path}")

#     tb_writer.close()
#     if args.use_wandb and HAS_WANDB:
#         wandb.finish()

# if __name__ == '__main__':
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--data_root', type=str, default='/yanghaochuan/data/1223pick_up_the_paper_cup.hdf5')
#     parser.add_argument('--output_dir', type=str, default='/yanghaochuan/checkpoints')
#     parser.add_argument('--stage_b_ckpt', type=str, default='/yanghaochuan/checkpoints/1223stageB_papercup.pt')
#     parser.add_argument('--batch_size', type=int, default=16)
#     parser.add_argument('--epochs', type=int, default=50)
#     parser.add_argument('--pred_horizon', type=int, default=64)
    
#     # === [æ–°å¢] å¯è§†åŒ–å¼€å…³ ===
#     parser.add_argument('--use_wandb', action='store_true', default=False, help="Enable WandB logging")
    
#     args = parser.parse_args()
#     train_stage_c(args)

import sys
import os
import torch
import torch.optim as optim
import argparse
import time
import numpy as np
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.amp import autocast
from diffusers import DDPMScheduler
from peft import LoraConfig, get_peft_model
from torch.utils.tensorboard import SummaryWriter 

# === [æ–°å¢] WandB æ£€æŸ¥ä¸å¯¼å…¥ ===
try:
    import wandb
    HAS_WANDB = True
except ImportError:
    HAS_WANDB = False
    print("âš ï¸ WandB not found. Install with `pip install wandb` for better visualization.")

# === æ€§èƒ½ä¼˜åŒ– ===
torch.backends.cuda.enable_flash_sdp(True)
torch.backends.cuda.enable_mem_efficient_sdp(True)
torch.backends.cuda.enable_math_sdp(False)

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model.fusion_encoder import FusionEncoder
from model.rdt_model import RDTWrapper
from utils.dataset_loader import RobotDataset
from losses.consistency_loss import compute_consistency_loss

# === è·¯å¾„é…ç½® ===
VIDEO_MAE_PATH = '/yanghaochuan/models/VideoMAEv2-Large'
RDT_PATH = '/yanghaochuan/models/rdt-1b'
STATS_PATH = '/yanghaochuan/data/1223dataset_stats.json'

def train_stage_c(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ====================================================
    # 0. åˆå§‹åŒ–å¯è§†åŒ–è®°å½•å™¨ (TensorBoard + WandB)
    # ====================================================
    # TensorBoard æ—¥å¿—ç›®å½•
    log_dir = os.path.join(args.output_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    tb_writer = SummaryWriter(log_dir=log_dir)
    print(f"ğŸ“ˆ TensorBoard logging to: {log_dir}")
    
    # WandB åˆå§‹åŒ–
    if args.use_wandb and HAS_WANDB:
        wandb.init(
            project="RDT-StageC-Joint",
            name=f"run_horizon{args.pred_horizon}_{int(time.time())}",
            config=vars(args),
            resume="allow" # å…è®¸ WandB æ–­ç‚¹ç»­ä¼ 
        )
        print("ğŸš€ WandB logging enabled.")
    
    print(f"=== Stage C Joint Training ===")
    
    # ====================================================
    # 1. æ¨¡å‹åŠ è½½ (FusionEncoder + RDT)
    # ====================================================
    print("Loading Models...")
    fusion_encoder = FusionEncoder(backbone_path=VIDEO_MAE_PATH, teacher_dim=1152, rdt_dim=768).to(device)
    
    # åŠ è½½ Stage B (å¦‚æœæœ‰)
    if args.stage_b_ckpt and os.path.exists(args.stage_b_ckpt):
        print(f"Loading Stage B: {args.stage_b_ckpt}")
        ckpt = torch.load(args.stage_b_ckpt, map_location='cpu')
        state_dict = ckpt['encoder_state_dict'] if 'encoder_state_dict' in ckpt else ckpt
        fusion_encoder.load_state_dict(state_dict, strict=False)
    
    # å†»ç»“ VideoMAE
    fusion_encoder.eval() 
    for param in fusion_encoder.parameters(): param.requires_grad = True 
    for param in fusion_encoder.backbone.parameters(): param.requires_grad = False
    if fusion_encoder.text_encoder:
        for p in fusion_encoder.text_encoder.parameters(): p.requires_grad = False

    # RDT Wrapper
    rdt_wrapper = RDTWrapper(action_dim=8, model_path=RDT_PATH, pred_horizon=args.pred_horizon).to(device)
    
    # RDT æƒé‡è‡ªåŠ¨åˆ‡ç‰‡åŠ è½½ (å¤„ç† Horizon 16 vs 64 çš„é—®é¢˜)
    if os.path.exists(RDT_PATH) or os.path.exists(os.path.join(RDT_PATH, "pytorch_model.bin")):
        rdt_file = RDT_PATH if os.path.isfile(RDT_PATH) else os.path.join(RDT_PATH, "pytorch_model.bin")
        if os.path.exists(rdt_file):
            print("Loading RDT weights with auto-slicing...")
            state_dict = torch.load(rdt_file, map_location='cpu')
            if 'x_pos_embed' in state_dict:
                ckpt_pos = state_dict['x_pos_embed']
                curr_pos = rdt_wrapper.rdt_model.x_pos_embed
                if ckpt_pos.shape != curr_pos.shape:
                    print(f"âœ‚ï¸ Slicing position embed: {ckpt_pos.shape} -> {curr_pos.shape}")
                    state_dict['x_pos_embed'] = ckpt_pos[:, :curr_pos.shape[1], :]
            rdt_wrapper.rdt_model.load_state_dict(state_dict, strict=False)

    # LoRA é…ç½®
    print("Applying LoRA...")
    peft_config = LoraConfig(
        r=16, lora_alpha=32, target_modules=["q_proj", "k_proj", "v_proj", "out_proj", "fc1", "fc2", "linear"], 
        lora_dropout=0.05, bias="none"
    )
    rdt_wrapper.rdt_model = get_peft_model(rdt_wrapper.rdt_model, peft_config)
    
    # ====================================================
    # 2. ä¼˜åŒ–å™¨ & è°ƒåº¦å™¨
    # ====================================================
    params = [
        {'params': filter(lambda p: p.requires_grad, rdt_wrapper.parameters()), 'lr': 1e-4},
        {'params': filter(lambda p: p.requires_grad, fusion_encoder.parameters()), 'lr': 1e-5}
    ]
    optimizer = optim.AdamW(params, weight_decay=1e-4)
    noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="squaredcos_cap_v2", prediction_type="sample")

    # ====================================================
    # ğŸŒŸ [å…³é”®ä¿®æ”¹] æ–­ç‚¹ç»­è®­é€»è¾‘ (Resume Training)
    # ====================================================
    start_epoch = 0
    if args.resume_from_checkpoint:
        if os.path.exists(args.resume_from_checkpoint):
            print(f"ğŸ”„ Resuming training from checkpoint: {args.resume_from_checkpoint}")
            checkpoint = torch.load(args.resume_from_checkpoint, map_location=device)
            
            # 1. æ¢å¤ Epoch
            if 'epoch' in checkpoint:
                start_epoch = checkpoint['epoch'] + 1
                print(f"   -> Resuming from Epoch {start_epoch}")
            
            # 2. æ¢å¤ RDT Policy (åŒ…å« LoRA æƒé‡)
            if 'rdt_state_dict' in checkpoint:
                rdt_wrapper.load_state_dict(checkpoint['rdt_state_dict'], strict=False)
                print("   -> RDT Policy (LoRA) weights restored.")
            
            # 3. æ¢å¤ Fusion Encoder (å¾®è°ƒåçš„æƒé‡)
            if 'encoder_state_dict' in checkpoint:
                fusion_encoder.load_state_dict(checkpoint['encoder_state_dict'], strict=False)
                print("   -> Fusion Encoder weights restored.")
                
            # 4. æ¢å¤ ä¼˜åŒ–å™¨çŠ¶æ€ (ä¿è¯åŠ¨é‡ä¸ä¸¢å¤±)
            if 'optimizer_state_dict' in checkpoint:
                try:
                    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                    print("   -> Optimizer state restored.")
                except Exception as e:
                    print(f"   âš ï¸ Optimizer load failed (skipping): {e}")
        else:
            print(f"âš ï¸ Checkpoint file not found: {args.resume_from_checkpoint}")

    # ====================================================
    # 3. æ•°æ®åŠ è½½
    # ====================================================
    print(f"Loading Dataset from {args.data_root}")
    dataset = RobotDataset(hdf5_path=args.data_root, window_size=16, pred_horizon=args.pred_horizon, stats_path=STATS_PATH)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)

    # ====================================================
    # 4. è®­ç»ƒå¾ªç¯ (å¸¦å¯è§†åŒ–)
    # ====================================================
    print(">>> Training Started <<<")
    # ä¿®æ­£ global_step ä»¥åŒ¹é… resume
    global_step = start_epoch * len(loader)
    
    # å¾ªç¯ä» start_epoch å¼€å§‹
    for epoch in range(start_epoch, args.epochs):
        rdt_wrapper.train()
        start_time = time.time()
        
        for i, batch in enumerate(loader):
            video = batch['video'].to(device, non_blocking=True) # [B, 2, 3, 16, H, W]
            state = batch['state'].to(device, non_blocking=True)
            text = batch['text_tokens'].to(device, non_blocking=True)
            ff = batch['first_frame'].to(device, non_blocking=True)
            actions = batch['action_target'].to(device, non_blocking=True)

            # Modality Dropout
            rand_val = torch.rand(1).item()
            mask_type = "None"
            if rand_val < 0.7:
                 video[:, 0] = 0.0  # Mask Main
                 mask_type = "Main_Masked"
            elif rand_val < 0.8:
                 video[:, 1] = 0.0  # Mask Wrist
                 mask_type = "Wrist_Masked"
            
            optimizer.zero_grad()
            
            with autocast('cuda', dtype=torch.bfloat16):
                # Forward
                e_t = fusion_encoder(video, text, state, ff)['e_t']
                
                # Loss
                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (actions.shape[0],), device=device).long()
                noise = torch.randn_like(actions)
                noisy_actions = noise_scheduler.add_noise(actions, noise, timesteps)
                
                conditions = {"e_t": e_t, "state": state[:, -1, :]}
                pred_noise = rdt_wrapper(noisy_actions, timesteps, conditions)
                
                loss_diff = F.mse_loss(pred_noise, noise)
                loss_cons = compute_consistency_loss(fusion_encoder, batch, device)
                total_loss = loss_diff + 0.1 * loss_cons

            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(rdt_wrapper.parameters(), 1.0)
            optimizer.step()
            
            # --- æ—¥å¿—è®°å½• ---
            if i % 10 == 0:
                print(f"Epoch {epoch} [{i}/{len(loader)}] Loss: {total_loss.item():.4f} (Diff: {loss_diff.item():.4f} Cons: {loss_cons.item():.4f})")
                
                tb_writer.add_scalar('Train/Total_Loss', total_loss.item(), global_step)
                tb_writer.add_scalar('Train/Diff_Loss', loss_diff.item(), global_step)
                tb_writer.add_scalar('Train/Cons_Loss', loss_cons.item(), global_step)
                
                if args.use_wandb and HAS_WANDB:
                    wandb.log({
                        "total_loss": total_loss.item(),
                        "diff_loss": loss_diff.item(),
                        "cons_loss": loss_cons.item(),
                        "epoch": epoch
                    }, step=global_step)
            
            # --- è§†é¢‘å¯è§†åŒ– (æ¯ 500 æ­¥ä¸€æ¬¡) ---
            if global_step % 500 == 0 and args.use_wandb and HAS_WANDB:
                try:
                    vid_sample = video[0].float().cpu().numpy() 
                    main_view = np.transpose(vid_sample[0], (1, 0, 2, 3)) # [T, C, H, W]
                    wrist_view = np.transpose(vid_sample[1], (1, 0, 2, 3))
                    combined_view = np.concatenate([main_view, wrist_view], axis=3) 
                    
                    wandb.log({
                        "input_video": wandb.Video((combined_view * 255).astype(np.uint8), fps=4, format="gif", caption=f"E{epoch}-S{i}: {mask_type}")
                    }, step=global_step)
                    print("ğŸ¥ Video sample uploaded to WandB.")
                except Exception as e:
                    print(f"âš ï¸ Video log failed: {e}")

            global_step += 1

            # ====================================================
            # ğŸ›‘ [æ–°å¢] è¾¾åˆ°æœ€å¤§æ­¥æ•°å¼ºåˆ¶åœæ­¢ (Max Train Steps)
            # ====================================================
            if args.max_train_steps is not None and global_step >= args.max_train_steps:
                print(f"ğŸ›‘ Reached max_train_steps ({args.max_train_steps}). Stopping training.")
                
                # å¼ºåˆ¶ä¿å­˜å½“å‰ Checkpoint
                save_path = os.path.join(args.output_dir, f"checkpoint_step_{global_step}.pt")
                torch.save({
                    'epoch': epoch,
                    'global_step': global_step,
                    'rdt_state_dict': rdt_wrapper.state_dict(),
                    'encoder_state_dict': fusion_encoder.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'pred_horizon': args.pred_horizon
                }, save_path)
                print(f"âœ… Final checkpoint saved to {save_path}")
                
                # å…³é—­è®°å½•å™¨å¹¶é€€å‡º
                tb_writer.close()
                if args.use_wandb and HAS_WANDB:
                    wandb.finish()
                return # é€€å‡ºè®­ç»ƒå‡½æ•°

        # ä¿å­˜ Checkpoint (æ¯ 2 ä¸ª Epoch æˆ– æœ€åä¸€ä¸ª)
        if epoch % 2 == 0 or epoch == args.epochs - 1:
            save_path = os.path.join(args.output_dir, f"epoch_{epoch}.pt")
            torch.save({
                'epoch': epoch,
                'rdt_state_dict': rdt_wrapper.state_dict(),
                'encoder_state_dict': fusion_encoder.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'pred_horizon': args.pred_horizon
            }, save_path)
            print(f"âœ… Saved to {save_path}")

    tb_writer.close()
    if args.use_wandb and HAS_WANDB:
        wandb.finish()

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_root', type=str, default='/yanghaochuan/data/1223pick_up_the_paper_cup.hdf5')
    parser.add_argument('--output_dir', type=str, default='/yanghaochuan/checkpoints')
    parser.add_argument('--stage_b_ckpt', type=str, default='/yanghaochuan/checkpoints/1223stageB_papercup.pt')
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--pred_horizon', type=int, default=64)
    
    # === å¯è§†åŒ– & ç»­è®­ & æ§åˆ¶ ===
    parser.add_argument('--use_wandb', action='store_true', default=False, help="Enable WandB logging")
    # ç»­è®­å‚æ•°
    parser.add_argument('--resume_from_checkpoint', type=str, default=None, 
                        help="Path to checkpoint to resume from (e.g. checkpoints/epoch_10.pt)")
    # [æ–°å¢] æœ€å¤§æ­¥æ•°åœæ­¢å‚æ•°
    parser.add_argument('--max_train_steps', type=int, default=None, 
                        help="Force stop training after this many global steps (e.g. 2500).")
    
    args = parser.parse_args()
    train_stage_c(args)