# import sys
# import os
# import torch
# import torch.optim as optim
# import argparse
# import time
# import numpy as np
# import torch.nn.functional as F
# from torch.utils.data import DataLoader
# from torch.amp import autocast
# from diffusers import DDPMScheduler
# from peft import LoraConfig, get_peft_model
# from torch.utils.tensorboard import SummaryWriter 

# # === [ç¯å¢ƒæ£€æŸ¥] WandB ===
# try:
#     import wandb
#     HAS_WANDB = True
# except ImportError:
#     HAS_WANDB = False
#     print("âš ï¸ WandB not found. Install with `pip install wandb` for better visualization.")

# # === æ€§èƒ½ä¼˜åŒ– ===
# torch.backends.cuda.enable_flash_sdp(True)
# torch.backends.cuda.enable_mem_efficient_sdp(True)
# torch.backends.cuda.enable_math_sdp(False)

# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# from model.fusion_encoder import FusionEncoder
# from model.rdt_model import RDTWrapper
# from utils.dataset_loader import RobotDataset
# from losses.consistency_loss import compute_consistency_loss

# # === è·¯å¾„é…ç½® (è¯·ç¡®ä¿è¿™äº›è·¯å¾„æ­£ç¡®) ===
# VIDEO_MAE_PATH = '/yanghaochuan/models/VideoMAEv2-Large'
# RDT_PATH = '/yanghaochuan/models/rdt-1b'
# STATS_PATH = '/yanghaochuan/data/1223dataset_stats.json'

# def train_stage_c(args):
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
#     # ====================================================
#     # 0. åˆå§‹åŒ–æ—¥å¿—
#     # ====================================================
#     log_dir = os.path.join(args.output_dir, "logs")
#     os.makedirs(log_dir, exist_ok=True)
#     tb_writer = SummaryWriter(log_dir=log_dir)
    
#     if args.use_wandb and HAS_WANDB:
#         wandb.init(
#             project="RDT-StageC-Joint",
#             # åå­—é‡Œå¸¦ä¸Š step å’Œ accï¼Œæ–¹ä¾¿åŒºåˆ†å®éªŒ
#             name=f"step{args.max_train_steps}_acc{args.gradient_accumulation_steps}_{int(time.time())}",
#             config=vars(args),
#             resume="allow"
#         )
    
#     print(f"=== Stage C Joint Training (Step-Based) ===")
#     print(f"ğŸ¯ Target: {args.max_train_steps} Global Steps")
#     print(f"ğŸ“¦ Physical Batch Size: {args.batch_size}")
#     print(f"ğŸ”‹ Gradient Accumulation: {args.gradient_accumulation_steps}")
#     print(f"ğŸ”¥ Effective Batch Size: {args.batch_size * args.gradient_accumulation_steps}")

#     # ====================================================
#     # 1. æ¨¡å‹åŠ è½½
#     # ====================================================
#     print("Loading Models...")
#     fusion_encoder = FusionEncoder(backbone_path=VIDEO_MAE_PATH, teacher_dim=1152, rdt_dim=768).to(device)
    
#     # åŠ è½½ Stage B (å¦‚æœæœ‰)
#     if args.stage_b_ckpt and os.path.exists(args.stage_b_ckpt):
#         print(f"Loading Stage B: {args.stage_b_ckpt}")
#         ckpt = torch.load(args.stage_b_ckpt, map_location='cpu')
#         state_dict = ckpt['encoder_state_dict'] if 'encoder_state_dict' in ckpt else ckpt
#         fusion_encoder.load_state_dict(state_dict, strict=False)
    
#     # å†»ç»“ VideoMAEï¼Œåªå¾®è°ƒ Adapter
#     fusion_encoder.eval() 
#     for param in fusion_encoder.parameters(): param.requires_grad = True 
#     for param in fusion_encoder.backbone.parameters(): param.requires_grad = False
#     if fusion_encoder.text_encoder:
#         for p in fusion_encoder.text_encoder.parameters(): p.requires_grad = False

#     # åŠ è½½ RDT
#     rdt_wrapper = RDTWrapper(action_dim=8, model_path=RDT_PATH, pred_horizon=args.pred_horizon).to(device)
    
#     # RDT æƒé‡åˆ‡ç‰‡åŠ è½½é€»è¾‘ (ä¿ç•™ä½ ä¹‹å‰çš„é€»è¾‘)
#     if os.path.exists(RDT_PATH) or os.path.exists(os.path.join(RDT_PATH, "pytorch_model.bin")):
#         rdt_file = RDT_PATH if os.path.isfile(RDT_PATH) else os.path.join(RDT_PATH, "pytorch_model.bin")
#         if os.path.exists(rdt_file):
#             print("Loading RDT weights with auto-slicing...")
#             state_dict = torch.load(rdt_file, map_location='cpu')
#             if 'x_pos_embed' in state_dict:
#                 ckpt_pos = state_dict['x_pos_embed']
#                 curr_pos = rdt_wrapper.rdt_model.x_pos_embed
#                 if ckpt_pos.shape != curr_pos.shape:
#                     print(f"âœ‚ï¸ Slicing position embed: {ckpt_pos.shape} -> {curr_pos.shape}")
#                     state_dict['x_pos_embed'] = ckpt_pos[:, :curr_pos.shape[1], :]
#             rdt_wrapper.rdt_model.load_state_dict(state_dict, strict=False)

#     # LoRA é…ç½®
#     print("Applying LoRA...")
#     peft_config = LoraConfig(
#         r=16, lora_alpha=32, target_modules=["q_proj", "k_proj", "v_proj", "out_proj", "fc1", "fc2", "linear"], 
#         lora_dropout=0.05, bias="none"
#     )
#     rdt_wrapper.rdt_model = get_peft_model(rdt_wrapper.rdt_model, peft_config)
    
#     # ====================================================
#     # 2. ä¼˜åŒ–å™¨ & è°ƒåº¦å™¨
#     # ====================================================
#     params = [
#         {'params': filter(lambda p: p.requires_grad, rdt_wrapper.parameters()), 'lr': 1e-4},
#         {'params': filter(lambda p: p.requires_grad, fusion_encoder.parameters()), 'lr': 1e-5}
#     ]
#     optimizer = optim.AdamW(params, weight_decay=1e-4)
    
#     # âš ï¸ è®­ç»ƒæ—¶ä¿æŒ 1000 æ­¥ï¼Œä¸è¦æ”¹è¿™é‡Œï¼æ¨ç†æ‰ç”¨ 25 æ­¥ã€‚
#     noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="squaredcos_cap_v2", prediction_type="sample")

#     # ====================================================
#     # 3. æ•°æ®åŠ è½½
#     # ====================================================
#     print(f"Loading Dataset from {args.data_root}")
#     dataset = RobotDataset(hdf5_path=args.data_root, window_size=16, pred_horizon=args.pred_horizon, stats_path=STATS_PATH)
#     # drop_last=True é˜²æ­¢æœ€åä¸€ä¸ª batch åªæœ‰å‡ ä¸ªæ ·æœ¬å¯¼è‡´æ¢¯åº¦ä¸ç¨³å®š
#     loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)

#     # ====================================================
#     # 4. ç²¾å‡†æ–­ç‚¹ç»­è®­é€»è¾‘
#     # ====================================================
#     global_step = 0
#     start_epoch = 0
#     resume_batch_idx = 0

#     if args.resume_from_checkpoint and os.path.exists(args.resume_from_checkpoint):
#         print(f"ğŸ”„ Resuming from: {args.resume_from_checkpoint}")
#         checkpoint = torch.load(args.resume_from_checkpoint, map_location=device)
        
#         # æ¢å¤æƒé‡
#         if 'rdt_state_dict' in checkpoint: rdt_wrapper.load_state_dict(checkpoint['rdt_state_dict'], strict=False)
#         if 'encoder_state_dict' in checkpoint: fusion_encoder.load_state_dict(checkpoint['encoder_state_dict'], strict=False)
#         if 'optimizer_state_dict' in checkpoint: optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
#         # æ¢å¤æ­¥æ•°
#         if 'global_step' in checkpoint:
#             global_step = checkpoint['global_step']
#             print(f"   -> Found Global Step: {global_step}")
            
#             # è®¡ç®—æˆ‘ä»¬éœ€è¦è·³è¿‡å¤šå°‘ä¸ªç‰©ç† Batch
#             # å…¬å¼ï¼šæ€»ç‰©ç†Batchæ•° = Global Step * æ¢¯åº¦ç´¯ç§¯æ¬¡æ•°
#             total_physical_batches = global_step * args.gradient_accumulation_steps
            
#             # è®¡ç®—å½“å‰ Epoch å’Œ Batch ç´¢å¼•
#             start_epoch = total_physical_batches // len(loader)
#             resume_batch_idx = total_physical_batches % len(loader)
            
#             print(f"   -> Resume Location: Epoch {start_epoch}, Batch {resume_batch_idx}")
#             print(f"   -> Ready to continue towards {args.max_train_steps} steps.")
        
#         elif 'epoch' in checkpoint:
#             # å…¼å®¹æ—§é€»è¾‘
#             start_epoch = checkpoint['epoch'] + 1
#             global_step = start_epoch * len(loader) // args.gradient_accumulation_steps
#             print(f"   -> Resuming from Epoch {start_epoch} (Approx. Step {global_step})")

#     # ====================================================
#     # 5. è®­ç»ƒå¾ªç¯ (16x4=64 Logic)
#     # ====================================================
#     print(">>> Training Started <<<")
    
#     # è¿™æ˜¯ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ•°å­—ï¼Œç¡®ä¿å¾ªç¯åªç”± max_train_steps ç»ˆæ­¢
#     total_epochs = 999999 
    
#     for epoch in range(start_epoch, total_epochs):
#         rdt_wrapper.train()
        
#         for i, batch in enumerate(loader):
#             # â© è·³è¿‡å·²è®­ç»ƒçš„æ•°æ® (ç²¾ç¡®ç»­è®­)
#             if epoch == start_epoch and i < resume_batch_idx:
#                 if i % 50 == 0: print(f"â© Skipping batch {i}/{len(loader)}...", end='\r')
#                 continue

#             # --- æ•°æ®å‡†å¤‡ ---
#             video = batch['video'].to(device, non_blocking=True)
#             state = batch['state'].to(device, non_blocking=True)
#             text = batch['text_tokens'].to(device, non_blocking=True)
#             ff = batch['first_frame'].to(device, non_blocking=True)
#             actions = batch['action_target'].to(device, non_blocking=True)

#             # Modality Dropout
#             rand_val = torch.rand(1).item()
#             mask_type = "None"
#             if rand_val < 0.7: 
#                 video[:, 0] = 0.0
#                 mask_type = "Main_Masked"
#             elif rand_val < 0.8: 
#                 video[:, 1] = 0.0
#                 mask_type = "Wrist_Masked"
            
#             # --- å‰å‘ä¼ æ’­ ---
#             with autocast('cuda', dtype=torch.bfloat16):
#                 # 1. Encode
#                 e_t = fusion_encoder(video, text, state, ff)['e_t']
                
#                 # 2. Noise & Target
#                 timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (actions.shape[0],), device=device).long()
#                 noise = torch.randn_like(actions)
#                 noisy_actions = noise_scheduler.add_noise(actions, noise, timesteps)
                
#                 # 3. Predict
#                 conditions = {"e_t": e_t, "state": state[:, -1, :]}
#                 pred_noise = rdt_wrapper(noisy_actions, timesteps, conditions)
                
#                 # 4. Loss Calculation
#                 loss_diff = F.mse_loss(pred_noise, noise)
#                 loss_cons = compute_consistency_loss(fusion_encoder, batch, device)
#                 total_loss = loss_diff + 0.1 * loss_cons
                
#                 # ğŸŒŸ [å…³é”®ç‚¹ 1] æ¢¯åº¦ç´¯ç§¯å½’ä¸€åŒ–
#                 # å› ä¸º backward ä¼šç´¯åŠ æ¢¯åº¦ï¼Œæ‰€ä»¥ Loss è¦é™¤ä»¥ç´¯ç§¯æ­¥æ•°ï¼Œä¿è¯å¹³å‡æ¢¯åº¦å¹…åº¦ä¸å˜
#                 total_loss = total_loss / args.gradient_accumulation_steps

#             # --- åå‘ä¼ æ’­ ---
#             total_loss.backward()

#             # ğŸŒŸ [å…³é”®ç‚¹ 2] å‚æ•°æ›´æ–°é€»è¾‘
#             # åªæœ‰å½“ç´¯ç§¯äº†è¶³å¤Ÿçš„æ­¥æ•°ï¼Œæˆ–è€… Epoch ç»“æŸæ—¶ï¼Œæ‰æ›´æ–°å‚æ•°
#             if (i + 1) % args.gradient_accumulation_steps == 0:
#                 torch.nn.utils.clip_grad_norm_(rdt_wrapper.parameters(), 1.0)
#                 optimizer.step()
#                 optimizer.zero_grad()
                
#                 # çœŸæ­£çš„ Step å¢åŠ äº† (Update Step)
#                 global_step += 1
                
#                 # --- æ—¥å¿—è®°å½• (è¿˜åŸ Loss æ•°å€¼æ–¹ä¾¿è§‚å¯Ÿ) ---
#                 if global_step % 10 == 0:
#                     real_loss = total_loss.item() * args.gradient_accumulation_steps
#                     real_diff = loss_diff.item()
#                     real_cons = loss_cons.item()
                    
#                     print(f"Step [{global_step}/{args.max_train_steps}] Loss: {real_loss:.4f} (Ep {epoch})")
                    
#                     tb_writer.add_scalar('Train/Total_Loss', real_loss, global_step)
#                     if args.use_wandb and HAS_WANDB:
#                         wandb.log({
#                             "total_loss": real_loss,
#                             "diff_loss": real_diff,
#                             "cons_loss": real_cons,
#                             "global_step": global_step,
#                             "epoch": epoch
#                         }, step=global_step)

#                 # --- è§†é¢‘å¯è§†åŒ– (æ¯ 500 æ­¥) ---
#                 if global_step % 500 == 0 and args.use_wandb and HAS_WANDB:
#                     try:
#                         vid_sample = video[0].float().cpu().numpy() 
#                         main_view = np.transpose(vid_sample[0], (1, 0, 2, 3))
#                         wrist_view = np.transpose(vid_sample[1], (1, 0, 2, 3))
#                         combined_view = np.concatenate([main_view, wrist_view], axis=3) 
#                         wandb.log({
#                             "input_video": wandb.Video((combined_view * 255).astype(np.uint8), fps=4, format="gif", caption=f"S{global_step}: {mask_type}")
#                         }, step=global_step)
#                     except: pass

#                 # --- ğŸ’¾ é˜¶æ®µæ€§ä¿å­˜ (Checkpointing) ---
#                 if global_step % args.checkpointing_steps == 0:
#                     save_path = os.path.join(args.output_dir, f"checkpoint_step_{global_step}.pt")
#                     torch.save({
#                         'epoch': epoch,
#                         'global_step': global_step, # ä¿å­˜å½“å‰ Global Step
#                         'rdt_state_dict': rdt_wrapper.state_dict(),
#                         'encoder_state_dict': fusion_encoder.state_dict(),
#                         'optimizer_state_dict': optimizer.state_dict(),
#                         'pred_horizon': args.pred_horizon
#                     }, save_path)
#                     print(f"ğŸ’¾ Checkpoint saved: {save_path}")

#                 # --- ğŸ›‘ åœæ­¢è®­ç»ƒ ---
#                 if global_step >= args.max_train_steps:
#                     print(f"ğŸ‰ Reached target {args.max_train_steps} steps. Training Finished.")
#                     # ä¿å­˜æœ€ç»ˆæ¨¡å‹
#                     final_path = os.path.join(args.output_dir, f"checkpoint_final_{global_step}.pt")
#                     torch.save({
#                         'epoch': epoch,
#                         'global_step': global_step,
#                         'rdt_state_dict': rdt_wrapper.state_dict(),
#                         'encoder_state_dict': fusion_encoder.state_dict()
#                     }, final_path)
#                     tb_writer.close()
#                     if args.use_wandb and HAS_WANDB: wandb.finish()
#                     return # é€€å‡ºå‡½æ•°ï¼Œç»“æŸè„šæœ¬

#     tb_writer.close()
#     if args.use_wandb and HAS_WANDB: wandb.finish()

# if __name__ == '__main__':
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--data_root', type=str, default='/yanghaochuan/data/1223pick_up_the_paper_cup.hdf5')
#     parser.add_argument('--output_dir', type=str, default='/yanghaochuan/1225checkpoints')
#     parser.add_argument('--stage_b_ckpt', type=str, default='/yanghaochuan/checkpoints/1223stageB_papercup.pt')
    
#     # ç‰©ç† Batch Size (æ˜¾å­˜é™åˆ¶ï¼Œä¿æŒ 16)
#     parser.add_argument('--batch_size', type=int, default=16)
#     parser.add_argument('--pred_horizon', type=int, default=64)
    
#     # === å…³é”®æ§åˆ¶å‚æ•° ===
#     # æ¢¯åº¦ç´¯ç§¯ï¼šè®¾ä¸º 4ï¼Œä½¿å¾— Effective Batch Size = 16 * 4 = 64
#     parser.add_argument('--gradient_accumulation_steps', type=int, default=4, 
#                         help="Number of updates steps to accumulate before update pass. (Effective BS = batch_size * this)")
    
#     # ç›®æ ‡æ€»æ­¥æ•° (Update Steps)
#     parser.add_argument('--max_train_steps', type=int, default=10000, 
#                         help="Total number of training steps (parameter updates) to perform.")
    
#     # æ¯å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡
#     parser.add_argument('--checkpointing_steps', type=int, default=500, 
#                         help="Save checkpoint every X updates.")
    
#     # ç»­è®­
#     parser.add_argument('--resume_from_checkpoint', type=str, default=None)
#     parser.add_argument('--use_wandb', action='store_true', default=False)
    
#     args = parser.parse_args()
#     train_stage_c(args)

import sys
import os
import torch
import torch.optim as optim
import argparse
import time
import numpy as np
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.amp import autocast
from diffusers import DDPMScheduler
from peft import LoraConfig, get_peft_model
from torch.utils.tensorboard import SummaryWriter 

# === [ç¯å¢ƒæ£€æŸ¥] WandB ===
try:
    import wandb
    HAS_WANDB = True
except ImportError:
    HAS_WANDB = False
    print("âš ï¸ WandB not found. Install with `pip install wandb` for better visualization.")

# === æ€§èƒ½ä¼˜åŒ– ===
torch.backends.cuda.enable_flash_sdp(True)
torch.backends.cuda.enable_mem_efficient_sdp(True)
torch.backends.cuda.enable_math_sdp(False)

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model.fusion_encoder import FusionEncoder
from model.rdt_model import RDTWrapper
from utils.dataset_loader import RobotDataset
from losses.consistency_loss import compute_consistency_loss
# ğŸš¨ [æ–°å¢] å¼•å…¥è’¸é¦ Loss ä½œä¸ºæ­£åˆ™é¡¹
from losses.distillation_loss import DistillationLoss

# === è·¯å¾„é…ç½® ===
VIDEO_MAE_PATH = '/yanghaochuan/models/VideoMAEv2-Large'
RDT_PATH = '/yanghaochuan/models/rdt-1b'
STATS_PATH = '/yanghaochuan/data/1223dataset_stats.json'

def train_stage_c(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ====================================================
    # 0. åˆå§‹åŒ–æ—¥å¿—
    # ====================================================
    log_dir = os.path.join(args.output_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    tb_writer = SummaryWriter(log_dir=log_dir)
    
    if args.use_wandb and HAS_WANDB:
        wandb.init(
            project="RDT-StageC-Joint",
            name=f"step{args.max_train_steps}_acc{args.gradient_accumulation_steps}_{int(time.time())}",
            config=vars(args),
            resume="allow"
        )
    
    print(f"=== Stage C Joint Training (Step-Based + Regularization) ===")
    print(f"ğŸ¯ Target: {args.max_train_steps} Global Steps")
    print(f"ğŸ“¦ Physical Batch Size: {args.batch_size}")
    print(f"ğŸ”‹ Gradient Accumulation: {args.gradient_accumulation_steps}")

    # ====================================================
    # 1. æ¨¡å‹åŠ è½½
    # ====================================================
    print("Loading Models...")
    fusion_encoder = FusionEncoder(backbone_path=VIDEO_MAE_PATH, teacher_dim=1152, rdt_dim=768).to(device)
    
    # åŠ è½½ Stage B
    if args.stage_b_ckpt and os.path.exists(args.stage_b_ckpt):
        print(f"Loading Stage B: {args.stage_b_ckpt}")
        ckpt = torch.load(args.stage_b_ckpt, map_location='cpu')
        state_dict = ckpt['encoder_state_dict'] if 'encoder_state_dict' in ckpt else ckpt
        # å…¼å®¹ key
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith("module."): new_state_dict[k[7:]] = v
            else: new_state_dict[k] = v
        fusion_encoder.load_state_dict(new_state_dict, strict=False)
    
    # å†»ç»“ VideoMAEï¼Œåªå¾®è°ƒ Adapter
    fusion_encoder.eval() 
    for param in fusion_encoder.parameters(): param.requires_grad = True 
    for param in fusion_encoder.backbone.parameters(): param.requires_grad = False
    if fusion_encoder.text_encoder:
        for p in fusion_encoder.text_encoder.parameters(): p.requires_grad = False

    # åŠ è½½ RDT
    rdt_wrapper = RDTWrapper(action_dim=8, model_path=RDT_PATH, pred_horizon=args.pred_horizon).to(device)
    
    # RDT æƒé‡åˆ‡ç‰‡åŠ è½½é€»è¾‘
    if os.path.exists(RDT_PATH) or os.path.exists(os.path.join(RDT_PATH, "pytorch_model.bin")):
        rdt_file = RDT_PATH if os.path.isfile(RDT_PATH) else os.path.join(RDT_PATH, "pytorch_model.bin")
        if os.path.exists(rdt_file):
            print("Loading RDT weights with auto-slicing...")
            state_dict = torch.load(rdt_file, map_location='cpu')
            if 'x_pos_embed' in state_dict:
                ckpt_pos = state_dict['x_pos_embed']
                curr_pos = rdt_wrapper.rdt_model.x_pos_embed
                if ckpt_pos.shape != curr_pos.shape:
                    print(f"âœ‚ï¸ Slicing position embed: {ckpt_pos.shape} -> {curr_pos.shape}")
                    state_dict['x_pos_embed'] = ckpt_pos[:, :curr_pos.shape[1], :]
            rdt_wrapper.rdt_model.load_state_dict(state_dict, strict=False)

    # LoRA é…ç½®
    print("Applying LoRA...")
    peft_config = LoraConfig(
        r=16, lora_alpha=32, target_modules=["q_proj", "k_proj", "v_proj", "out_proj", "fc1", "fc2", "linear"], 
        lora_dropout=0.05, bias="none"
    )
    rdt_wrapper.rdt_model = get_peft_model(rdt_wrapper.rdt_model, peft_config)
    
    # ====================================================
    # 2. ä¼˜åŒ–å™¨ & Loss
    # ====================================================
    params = [
        {'params': filter(lambda p: p.requires_grad, rdt_wrapper.parameters()), 'lr': 1e-4},
        {'params': filter(lambda p: p.requires_grad, fusion_encoder.parameters()), 'lr': 1e-5}
    ]
    optimizer = optim.AdamW(params, weight_decay=1e-4)
    
    noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="squaredcos_cap_v2", prediction_type="sample")

    # ğŸš¨ [æ–°å¢] è’¸é¦ Loss (ç”¨äºæ­£åˆ™åŒ–)
    distill_fn = DistillationLoss()

    # ====================================================
    # 3. æ•°æ®åŠ è½½
    # ====================================================
    print(f"Loading Dataset from {args.data_root}")
    dataset = RobotDataset(hdf5_path=args.data_root, window_size=16, pred_horizon=args.pred_horizon, stats_path=STATS_PATH)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)

    # ====================================================
    # 4. ç²¾å‡†æ–­ç‚¹ç»­è®­
    # ====================================================
    global_step = 0
    start_epoch = 0
    resume_batch_idx = 0

    if args.resume_from_checkpoint and os.path.exists(args.resume_from_checkpoint):
        print(f"ğŸ”„ Resuming from: {args.resume_from_checkpoint}")
        checkpoint = torch.load(args.resume_from_checkpoint, map_location=device)
        
        if 'rdt_state_dict' in checkpoint: rdt_wrapper.load_state_dict(checkpoint['rdt_state_dict'], strict=False)
        if 'encoder_state_dict' in checkpoint: fusion_encoder.load_state_dict(checkpoint['encoder_state_dict'], strict=False)
        if 'optimizer_state_dict' in checkpoint: optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if 'global_step' in checkpoint:
            global_step = checkpoint['global_step']
            total_physical_batches = global_step * args.gradient_accumulation_steps
            start_epoch = total_physical_batches // len(loader)
            resume_batch_idx = total_physical_batches % len(loader)
            print(f"   -> Resume Location: Epoch {start_epoch}, Batch {resume_batch_idx}")
        elif 'epoch' in checkpoint:
            start_epoch = checkpoint['epoch'] + 1
            global_step = start_epoch * len(loader) // args.gradient_accumulation_steps
            print(f"   -> Resuming from Epoch {start_epoch} (Approx. Step {global_step})")

    # ====================================================
    # 5. è®­ç»ƒå¾ªç¯
    # ====================================================
    print(">>> Training Started <<<")
    total_epochs = 999999 
    
    for epoch in range(start_epoch, total_epochs):
        rdt_wrapper.train()
        
        for i, batch in enumerate(loader):
            if epoch == start_epoch and i < resume_batch_idx:
                if i % 50 == 0: print(f"â© Skipping batch {i}/{len(loader)}...", end='\r')
                continue

            # --- æ•°æ®å‡†å¤‡ ---
            video = batch['video'].to(device, non_blocking=True) # [B, 2, C, T, H, W]
            state = batch['state'].to(device, non_blocking=True)
            text = batch['text_tokens'].to(device, non_blocking=True)
            ff = batch['first_frame'].to(device, non_blocking=True)
            actions = batch['action_target'].to(device, non_blocking=True)

            # --- Teacher Features (ç”¨äºæ­£åˆ™åŒ–) ---
            real_siglip = batch['teacher_siglip'].to(device, non_blocking=True)
            real_exo = batch['teacher_exo'].to(device, non_blocking=True)
            siglip_target = torch.mean(real_siglip, dim=1)
            exo_target = torch.mean(real_exo, dim=1)
            teacher_feats = {"siglip_features": siglip_target, "exo_features": exo_target}

            # ==========================================================
            # ğŸš¨ [å…³é”®ä¿®å¤] Modality Dropout (æ•°æ®å…‹éš†ä¸åŒæ­¥ Mask)
            # ==========================================================
            rand_val = torch.rand(1).item()
            mask_type = "Teacher_Mode"
            
            # 1. å¿…é¡» Clone! å¦åˆ™ä¼šæ±¡æŸ“ batch['video']ï¼Œå¯¼è‡´ Consistency Loss é‡Œçš„ Teacher ä¹Ÿæ˜¯é»‘çš„
            video_input = video.clone()
            ff_input = ff.clone()
            
            if rand_val < 0.7: 
                # 70% æ¦‚ç‡ï¼šæ¨¡æ‹Ÿæ¨ç† (Student Mode)
                video_input[:, 0] = 0.0
                ff_input[:, 0] = 0.0     # <--- ğŸš¨ åŒæ­¥ Mask é¦–å¸§ (é˜²ä½œå¼Š)
                mask_type = "Main_Masked"
            elif rand_val < 0.8: 
                # 10% æ¦‚ç‡ï¼šæ‰‹è…•é®æŒ¡
                video_input[:, 1] = 0.0
                ff_input[:, 1] = 0.0     # <--- ğŸš¨ åŒæ­¥ Mask é¦–å¸§
                mask_type = "Wrist_Masked"
            # 20% æ¦‚ç‡ï¼šTeacher Mode (å…¨å¯è§)
            
            # ==========================================================
            
            # --- å‰å‘ä¼ æ’­ ---
            with autocast('cuda', dtype=torch.bfloat16):
                # 1. Encode (ä½¿ç”¨ Mask åçš„è¾“å…¥)
                # è¿”å›å®Œæ•´ dict ä»¥ä¾¿è®¡ç®— Distill Loss
                encoder_out = fusion_encoder(video_input, text, state, ff_input)
                e_t = encoder_out['e_t']
                
                # 2. RDT Forward (Action Loss)
                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (actions.shape[0],), device=device).long()
                noise = torch.randn_like(actions)
                noisy_actions = noise_scheduler.add_noise(actions, noise, timesteps)
                
                conditions = {"e_t": e_t, "state": state[:, -1, :]}
                pred_noise = rdt_wrapper(noisy_actions, timesteps, conditions)
                
                # --- Loss Calculation ---
                
                # Loss 1: Action Diffusion Loss
                loss_diff = F.mse_loss(pred_noise, noise)
                
                # Loss 2: Consistency Loss (Brain Completion)
                # ä½¿ç”¨åŸå§‹ batch (åŒ…å«æœª Mask çš„æ•°æ®)ï¼Œå‡½æ•°å†…éƒ¨ä¼šè‡ªå·±å¤„ç† Student/Teacher æ„å»º
                loss_cons = compute_consistency_loss(fusion_encoder, batch, device)
                
                # Loss 3: Distillation Regularization (Don't forget semantics)
                # å¼ºè¿«å½“å‰ Mask çŠ¶æ€ä¸‹çš„ encoder_out ä¾ç„¶èƒ½æ¢å¤å‡ºå…¨å±€è¯­ä¹‰
                # è¿™å®Œå…¨å¤ç”¨äº† Stage B çš„é€»è¾‘
                loss_distill_reg, _ = distill_fn(encoder_out, teacher_feats)
                
                # ğŸŒŸ ç»„åˆ Loss
                # diff: 1.0 (ä¸»ä»»åŠ¡)
                # cons: 0.1 (è¾…åŠ©è„‘è¡¥)
                # distill: 0.05 (è¾…åŠ©è¯­ä¹‰é”šå®šï¼Œé˜²æ­¢æ¼‚ç§»)
                total_loss = loss_diff + 0.1 * loss_cons + 0.05 * loss_distill_reg
                
                # æ¢¯åº¦ç´¯ç§¯å½’ä¸€åŒ–
                total_loss = total_loss / args.gradient_accumulation_steps

            # --- åå‘ä¼ æ’­ ---
            total_loss.backward()

            # --- å‚æ•°æ›´æ–° ---
            if (i + 1) % args.gradient_accumulation_steps == 0:
                torch.nn.utils.clip_grad_norm_(rdt_wrapper.parameters(), 1.0)
                optimizer.step()
                optimizer.zero_grad()
                
                global_step += 1
                
                # --- æ—¥å¿—è®°å½• ---
                if global_step % 10 == 0:
                    real_loss = total_loss.item() * args.gradient_accumulation_steps
                    
                    print(f"Step [{global_step}/{args.max_train_steps}] Loss: {real_loss:.4f} | Diff: {loss_diff.item():.4f} | Cons: {loss_cons.item():.4f} | Reg: {loss_distill_reg.item():.4f}")
                    
                    tb_writer.add_scalar('Train/Total_Loss', real_loss, global_step)
                    if args.use_wandb and HAS_WANDB:
                        wandb.log({
                            "total_loss": real_loss,
                            "diff_loss": loss_diff.item(),
                            "cons_loss": loss_cons.item(),
                            "distill_reg_loss": loss_distill_reg.item(),
                            "global_step": global_step,
                            "epoch": epoch,
                            "lr": optimizer.param_groups[0]['lr']
                        }, step=global_step)

                # --- è§†é¢‘å¯è§†åŒ– ---
                if global_step % 500 == 0 and args.use_wandb and HAS_WANDB:
                    try:
                        # å¯è§†åŒ–çœŸæ­£å–‚ç»™ RDT çš„æ•°æ® (video_input)
                        vid_sample = video_input[0].float().cpu().numpy() 
                        main_view = np.transpose(vid_sample[0], (1, 0, 2, 3))
                        wrist_view = np.transpose(vid_sample[1], (1, 0, 2, 3))
                        combined_view = np.concatenate([main_view, wrist_view], axis=3) 
                        wandb.log({
                            "input_monitor": wandb.Video((combined_view * 255).astype(np.uint8), fps=4, format="gif", caption=f"S{global_step}: {mask_type}")
                        }, step=global_step)
                    except: pass

                # --- Checkpoint ä¿å­˜ ---
                if global_step % args.checkpointing_steps == 0:
                    save_path = os.path.join(args.output_dir, f"stageC_step_{global_step}.pt")
                    torch.save({
                        'epoch': epoch,
                        'global_step': global_step, 
                        'rdt_state_dict': rdt_wrapper.state_dict(),
                        'encoder_state_dict': fusion_encoder.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'pred_horizon': args.pred_horizon
                    }, save_path)
                    print(f"ğŸ’¾ Checkpoint saved: {save_path}")

                # --- ç»“æŸè®­ç»ƒ ---
                if global_step >= args.max_train_steps:
                    print(f"ğŸ‰ Reached target {args.max_train_steps} steps. Training Finished.")
                    final_path = os.path.join(args.output_dir, f"stageC_final_{global_step}.pt")
                    torch.save({
                        'epoch': epoch,
                        'global_step': global_step,
                        'rdt_state_dict': rdt_wrapper.state_dict(),
                        'encoder_state_dict': fusion_encoder.state_dict()
                    }, final_path)
                    tb_writer.close()
                    if args.use_wandb and HAS_WANDB: wandb.finish()
                    return 

    tb_writer.close()
    if args.use_wandb and HAS_WANDB: wandb.finish()

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_root', type=str, default='/yanghaochuan/data/1223pick_up_the_paper_cup.hdf5')
    parser.add_argument('--output_dir', type=str, default='/yanghaochuan/1225checkpoints')
    parser.add_argument('--stage_b_ckpt', type=str, default='/yanghaochuan/checkpoints/1223stageB_papercup.pt')
    
    # ç‰©ç† Batch Size (æ˜¾å­˜é™åˆ¶ï¼Œä¿æŒ 16)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--pred_horizon', type=int, default=64)
    
    # === å…³é”®æ§åˆ¶å‚æ•° ===
    parser.add_argument('--gradient_accumulation_steps', type=int, default=4, 
                        help="Number of updates steps to accumulate before update pass. (Effective BS = batch_size * this)")
    
    parser.add_argument('--max_train_steps', type=int, default=10000, 
                        help="Total number of training steps (parameter updates) to perform.")
    
    parser.add_argument('--checkpointing_steps', type=int, default=500, 
                        help="Save checkpoint every X updates.")
    
    parser.add_argument('--resume_from_checkpoint', type=str, default=None)
    parser.add_argument('--use_wandb', action='store_true', default=False)
    
    args = parser.parse_args()
    train_stage_c(args)