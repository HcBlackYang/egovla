# utils/compute_stats.py
import h5py
import numpy as np
import argparse
import json
import os
from tqdm import tqdm

def compute_stats(args):
    print(f"Computing stats for {args.data_root} ...")
    
    all_qpos = []
    
    with h5py.File(args.data_root, 'r') as f:
        demos = list(f['data'].keys())
        for demo_key in tqdm(demos):
            demo_grp = f['data'][demo_key]
            # è¯»å–æ‰€æœ‰å…³èŠ‚è§’åº¦
            qpos = demo_grp['obs']['robot0_joint_pos'][:] 
            
            # å¤„ç†å¤¹çˆªæ‹¼æ¥é€»è¾‘ (7ç»´ -> 8ç»´)
            if qpos.shape[1] == 7:
                # å°è¯•è¯»å– gripper
                if 'robot0_gripper_qpos' in demo_grp['obs']:
                    gripper = demo_grp['obs']['robot0_gripper_qpos'][:]
                elif 'gripper_states' in demo_grp['obs']:
                     gripper = demo_grp['obs']['gripper_states'][:]
                else:
                    # é»˜è®¤å…¨ 0
                    gripper = np.zeros((qpos.shape[0], 1))
                
                # æ‹¼æ¥æˆ 8 ç»´
                if gripper.ndim == 1: gripper = gripper[:, None]
                qpos = np.concatenate([qpos, gripper], axis=1)
                
            all_qpos.append(qpos)
            
    # æ‹¼æ¥æ‰€æœ‰æ•°æ® [Total_Frames, 8]
    all_qpos = np.concatenate(all_qpos, axis=0) 
    
    # 1. è®¡ç®—åŸå§‹ç»Ÿè®¡é‡
    mean = np.mean(all_qpos, axis=0)
    std = np.std(all_qpos, axis=0)
    
    # =========================================================
    # ğŸš¨ [å…³é”®ä¿®å¤] å¼ºåˆ¶è¦†ç›–å¤¹çˆªç»Ÿè®¡é‡ (å½’ä¸€åŒ–é™·é˜±ä¿®å¤)
    # =========================================================
    # ç›®çš„ï¼šå¿½ç•¥æ•°æ®çš„ç»Ÿè®¡åˆ†å¸ƒï¼Œå¼ºåˆ¶å°†å¤¹çˆªçš„ç‰©ç†èŒƒå›´æ˜ å°„åˆ° [-1, 1]
    # è¿™æ ·æ¨¡å‹ä¸éœ€è¦é¢„æµ‹æç«¯çš„æ•°å€¼ (å¦‚ -4.75)ï¼Œåªéœ€è¦é¢„æµ‹ -1 æˆ– 1
    
    gripper_idx = 7
    # è·å–å¤¹çˆªçš„ç‰©ç†æå€¼ (ä¾‹å¦‚: 0.0 ~ 0.08 æˆ– -1 ~ 1)
    gripper_data = all_qpos[:, gripper_idx]
    g_min = np.min(gripper_data)
    g_max = np.max(gripper_data)
    
    print(f"ğŸ“Š æ£€æµ‹åˆ°å¤¹çˆªç‰©ç†èŒƒå›´: Min={g_min:.4f}, Max={g_max:.4f}")
    
    # è®¡ç®—æ–°çš„æ˜ å°„å‚æ•°
    # å…¬å¼: normalized = (x - mean) / std
    # æˆ‘ä»¬å¸Œæœ›: x=g_max -> 1, x=g_min -> -1
    # è§£æ–¹ç¨‹å¾—:
    new_mean = (g_max + g_min) / 2.0
    new_std  = (g_max - g_min) / 2.0
    
    # é˜²æ­¢é™¤ä»¥0 (å¦‚æœå¤¹çˆªå…¨ç¨‹ä¸åŠ¨)
    if new_std < 1e-6: 
        new_std = 1.0
        print("âš ï¸ è­¦å‘Šï¼šå¤¹çˆªæ•°æ®ä¼¼ä¹æ²¡æœ‰å˜åŒ–ï¼ŒStdè®¾ä¸º1.0")

    # è¦†ç›–
    mean[gripper_idx] = new_mean
    std[gripper_idx]  = new_std
    
    print(f"âœ… å·²ä¿®æ­£å¤¹çˆªç»Ÿè®¡é‡ -> Mean: {mean[gripper_idx]:.4f}, Std: {std[gripper_idx]:.4f}")
    # =========================================================
    
    stats = {
        "action_mean": mean.tolist(),
        "action_std": std.tolist()
    }
    
    # ä¿å­˜
    with open(args.save_path, 'w') as f:
        json.dump(stats, f, indent=4)
        
    print(f"âœ… Stats saved to {args.save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_root', type=str, required=True, help="Path to HDF5 file")
    parser.add_argument('--save_path', type=str, default='/yanghaochuan/data/111dataset_stats.json')
    args = parser.parse_args()
    compute_stats(args)
