# # utils/compute_stats.py
# import h5py
# import numpy as np
# import argparse
# import json
# import os
# from tqdm import tqdm

# def compute_stats(args):
#     print(f"Computing stats for {args.data_root} ...")
    
#     all_qpos = []
    
#     with h5py.File(args.data_root, 'r') as f:
#         demos = list(f['data'].keys())
#         for demo_key in tqdm(demos):
#             demo_grp = f['data'][demo_key]
#             # è¯»å–æ‰€æœ‰å…³èŠ‚è§’åº¦
#             qpos = demo_grp['obs']['robot0_joint_pos'][:] 
            
#             # å¤„ç†å¤¹çˆªæ‹¼æ¥é€»è¾‘ (7ç»´ -> 8ç»´)
#             if qpos.shape[1] == 7:
#                 # å°è¯•è¯»å– gripper
#                 if 'robot0_gripper_qpos' in demo_grp['obs']:
#                     gripper = demo_grp['obs']['robot0_gripper_qpos'][:]
#                 elif 'gripper_states' in demo_grp['obs']:
#                      gripper = demo_grp['obs']['gripper_states'][:]
#                 else:
#                     # é»˜è®¤å…¨ 0
#                     gripper = np.zeros((qpos.shape[0], 1))
                
#                 # æ‹¼æ¥æˆ 8 ç»´
#                 if gripper.ndim == 1: gripper = gripper[:, None]
#                 qpos = np.concatenate([qpos, gripper], axis=1)
                
#             all_qpos.append(qpos)
            
#     # æ‹¼æ¥æ‰€æœ‰æ•°æ® [Total_Frames, 8]
#     all_qpos = np.concatenate(all_qpos, axis=0) 
    
#     # 1. è®¡ç®—åŸå§‹ç»Ÿè®¡é‡
#     mean = np.mean(all_qpos, axis=0)
#     std = np.std(all_qpos, axis=0)
    
#     # =========================================================
#     # ğŸš¨ [å…³é”®ä¿®å¤] å¼ºåˆ¶è¦†ç›–å¤¹çˆªç»Ÿè®¡é‡ (å½’ä¸€åŒ–é™·é˜±ä¿®å¤)
#     # =========================================================
#     # ç›®çš„ï¼šå¿½ç•¥æ•°æ®çš„ç»Ÿè®¡åˆ†å¸ƒï¼Œå¼ºåˆ¶å°†å¤¹çˆªçš„ç‰©ç†èŒƒå›´æ˜ å°„åˆ° [-1, 1]
#     # è¿™æ ·æ¨¡å‹ä¸éœ€è¦é¢„æµ‹æç«¯çš„æ•°å€¼ (å¦‚ -4.75)ï¼Œåªéœ€è¦é¢„æµ‹ -1 æˆ– 1
    
#     gripper_idx = 7
#     # è·å–å¤¹çˆªçš„ç‰©ç†æå€¼ (ä¾‹å¦‚: 0.0 ~ 0.08 æˆ– -1 ~ 1)
#     gripper_data = all_qpos[:, gripper_idx]
#     g_min = np.min(gripper_data)
#     g_max = np.max(gripper_data)
    
#     print(f"ğŸ“Š æ£€æµ‹åˆ°å¤¹çˆªç‰©ç†èŒƒå›´: Min={g_min:.4f}, Max={g_max:.4f}")
    
#     # è®¡ç®—æ–°çš„æ˜ å°„å‚æ•°
#     # å…¬å¼: normalized = (x - mean) / std
#     # æˆ‘ä»¬å¸Œæœ›: x=g_max -> 1, x=g_min -> -1
#     # è§£æ–¹ç¨‹å¾—:
#     new_mean = (g_max + g_min) / 2.0
#     new_std  = (g_max - g_min) / 2.0
    
#     # é˜²æ­¢é™¤ä»¥0 (å¦‚æœå¤¹çˆªå…¨ç¨‹ä¸åŠ¨)
#     if new_std < 1e-6: 
#         new_std = 1.0
#         print("âš ï¸ è­¦å‘Šï¼šå¤¹çˆªæ•°æ®ä¼¼ä¹æ²¡æœ‰å˜åŒ–ï¼ŒStdè®¾ä¸º1.0")

#     # è¦†ç›–
#     mean[gripper_idx] = new_mean
#     std[gripper_idx]  = new_std
    
#     print(f"âœ… å·²ä¿®æ­£å¤¹çˆªç»Ÿè®¡é‡ -> Mean: {mean[gripper_idx]:.4f}, Std: {std[gripper_idx]:.4f}")
#     # =========================================================
    
#     stats = {
#         "action_mean": mean.tolist(),
#         "action_std": std.tolist()
#     }
    
#     # ä¿å­˜
#     with open(args.save_path, 'w') as f:
#         json.dump(stats, f, indent=4)
        
#     print(f"âœ… Stats saved to {args.save_path}")

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--data_root', type=str, required=True, help="Path to HDF5 file")
#     parser.add_argument('--save_path', type=str, default='/yanghaochuan/data/115dataset_stats.json')
#     args = parser.parse_args()
#     compute_stats(args)

# utils/compute_stats.py
import h5py
import numpy as np
import argparse
import json
import os
from tqdm import tqdm

def compute_stats(args):
    print(f"Computing stats for {args.data_root} ...")
    print(f"âš–ï¸  Balancing Strategy: Type A (Weight 1) | Type B (Weight 4)")
    
    all_qpos = []
    type_a_count = 0
    type_b_count = 0
    
    with h5py.File(args.data_root, 'r') as f:
        demos = list(f['data'].keys())
        
        for demo_key in tqdm(demos):
            demo_grp = f['data'][demo_key]
            
            # --- 1. è¯»å–åŸå§‹æ•°æ® ---
            # è¯»å–æ‰€æœ‰å…³èŠ‚è§’åº¦
            qpos = demo_grp['obs']['robot0_joint_pos'][:] 
            
            # å¤„ç†å¤¹çˆªæ‹¼æ¥é€»è¾‘ (7ç»´ -> 8ç»´)
            if qpos.shape[1] == 7:
                # å°è¯•è¯»å– gripper
                if 'robot0_gripper_qpos' in demo_grp['obs']:
                    gripper = demo_grp['obs']['robot0_gripper_qpos'][:]
                elif 'gripper_states' in demo_grp['obs']:
                     gripper = demo_grp['obs']['gripper_states'][:]
                else:
                    # é»˜è®¤å…¨ 0
                    gripper = np.zeros((qpos.shape[0], 1))
                
                # æ‹¼æ¥æˆ 8 ç»´
                if gripper.ndim == 1: gripper = gripper[:, None]
                qpos = np.concatenate([qpos, gripper], axis=1)
            
            # --- 2. åˆ¤å®šç±»å‹å¹¶åŠ æƒ ---
            # å‡è®¾å‘½åè§„åˆ™æ˜¯ demo_0, demo_1 ...
            try:
                idx = int(demo_key.split('_')[1])
            except:
                idx = 0 # Fallback
            
            # Type B (High Start) = ID is multiple of 5
            if idx % 5 == 0:
                weight = 4
                type_b_count += 1
            else:
                weight = 1
                type_a_count += 1
                
            # --- 3. åŠ æƒæ”¶é›† ---
            # å°†æ•°æ®é‡å¤ weight æ¬¡åŠ å…¥åˆ—è¡¨
            # æ³¨æ„ï¼šè¿™ä¸ä¼šæ˜¾è‘—å¢åŠ å†…å­˜å‹åŠ›ï¼Œå› ä¸ºåªæ˜¯å¼•ç”¨æˆ–å°è§„æ¨¡æ‹·è´ (qposæ•°æ®é‡é€šå¸¸ä¸å¤§)
            for _ in range(weight):
                all_qpos.append(qpos)
            
    print(f"ğŸ“Š Original Demos: Type A={type_a_count}, Type B={type_b_count}")
    print(f"âš–ï¸  Weighted Ratio: {type_a_count * 1} : {type_b_count * 4} (Approx 1:1)")

    # æ‹¼æ¥æ‰€æœ‰æ•°æ® [Total_Weighted_Frames, 8]
    all_qpos_concat = np.concatenate(all_qpos, axis=0) 
    
    # 4. è®¡ç®—ç»Ÿè®¡é‡
    mean = np.mean(all_qpos_concat, axis=0)
    std = np.std(all_qpos_concat, axis=0)
    
    # =========================================================
    # ğŸš¨ [ä¿ç•™] å¼ºåˆ¶è¦†ç›–å¤¹çˆªç»Ÿè®¡é‡ (å½’ä¸€åŒ–ä¿®å¤)
    # =========================================================
    gripper_idx = 7
    gripper_data = all_qpos_concat[:, gripper_idx]
    g_min = np.min(gripper_data)
    g_max = np.max(gripper_data)
    
    print(f"ğŸ“Š Detected Gripper Range: Min={g_min:.4f}, Max={g_max:.4f}")
    
    # æ˜ å°„åˆ° [-1, 1]
    new_mean = (g_max + g_min) / 2.0
    new_std  = (g_max - g_min) / 2.0
    
    if new_std < 1e-6: 
        new_std = 1.0
        print("âš ï¸ Warning: Gripper static, Std set to 1.0")

    mean[gripper_idx] = new_mean
    std[gripper_idx]  = new_std
    
    print(f"âœ… Corrected Gripper Stats -> Mean: {mean[gripper_idx]:.4f}, Std: {std[gripper_idx]:.4f}")
    
    # 5. ä¿å­˜
    stats = {
        "action_mean": mean.tolist(),
        "action_std": std.tolist()
    }
    
    with open(args.save_path, 'w') as f:
        json.dump(stats, f, indent=4)
        
    print(f"âœ… Weighted Stats saved to {args.save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_root', type=str, required=True, help="Path to HDF5 file")
    # å»ºè®®ä¿å­˜ä¸ºæ–°æ–‡ä»¶åï¼Œä»¥å…è¦†ç›–æ—§çš„å¯¹æ¯”
    parser.add_argument('--save_path', type=str, default='/yanghaochuan/data/121dataset_stats.json')
    args = parser.parse_args()
    compute_stats(args)